{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability and Information Theory\n",
    "\n",
    "p1 (page 53)\n",
    "* 이 챕처에서는 probability theory와 imformation theory에 대해 설명함\n",
    "\n",
    "p2 (page 53)\n",
    "* Probability theory는 수학적인 프레임워크로서 불확실한 상태를 나타내는데 사용됨\n",
    "* Probability theory는 불확실성의 양에 대한 평균을 보여주고, 새로운 불확실한 상태를 이끌어내기위한 자명한 진리를 제공함\n",
    "* AI쪽에서는 2가지 방법에서 확률이론을 사용함\n",
    "    * 확률이론은 AI시스템이 어떻게 추론하는지 알려주는 이론으로 따라서 확률이론을 사용하여 도출된 다양한 표현식을 계산하거나 근사하도록 알고리즘을 설계함\n",
    "    * 확률과 통계를 학문적으로 제안된 AI시스템의 동작을 조사하는데 사용됨\n",
    "\n",
    "p3 (page 53)\n",
    "* 확률이론은 과학과 공학분야에서 기본 도구임\n",
    "* 이 챕처에서는 확률 이론에 대한 노출이 제한적인 스프트웨어 엔지니어링의 독자가 이 책의 내용을 이해할 수 있도록 이 장을 제공함\n",
    "\n",
    "p4 (page 53)\n",
    "* 확률이론은 불확실한 생태와 이유를 제시할 수 있게 하지만, 정보 이론은 확률 분포에서 불확실성의 양을 정량화 할수 있게함\n",
    "\n",
    "p5 (page 53)\n",
    "* 이미 확률이론과 정보이론에 익숙하다면 이 장을 넘어가도 됨(3.14를 제외하고)\n",
    "* 만약 선행지식이 없다면, 이 챕터는 딥터닝공부를 하는데 충분히 좋지만, 추가적인 자료들도 추천함\n",
    "\n",
    "\n",
    "## 3.1 Why Probability\n",
    "p1 (page 54)\n",
    "* 많은 컴퓨터공학분야는 대부분 결정론적이고 확실한 엔터티를 가짐\n",
    "* 프로그래머는 보통 CPU가 각각의 머신 명령어를 완벽하게 실한한다고 가정할 수 있음\n",
    "* 하드웨어 오류가 발생하지만 대부분의 소프트웨어 응용 그로그램에서 이를 설명하기 위해 하드웨어를 설계할 필요는 없음\n",
    "\n",
    "p2 (page 54)\n",
    "* 1980년애 이후 확률을 사용하여 불확실성을 정량화하기위한 시도들이 나타남\n",
    "\n",
    "p3 (page 54)\n",
    "* 불확실성이 존재할 때, 추론할 수 있는 능력이 필요함\n",
    "* 하지만, 실제로 모든 발행사는 상황을 고려하기는 어려움\n",
    "\n",
    "    불확실성의 원인은 세가지 있음\n",
    "    1. 모델링중인 시스템에서 고유 확률: 양자 역학에 대한 대부분의 해석은 원자 입자의 역할을 확률적임\n",
    "    2. 불완전한 관측성: 결적적인 시스템조차도 시스템의 동작을 유발하는 모든 변수를 관찰할 수 없을 때, 확률적으로 보일 수 있음, 예를들어, 세개의 문이 있고 두개의 문에는 염소, 하나의 문에는 차를 놔두고 경품추첨이 있다면, 이걸 선택하는 사람 입장에서 선택은  결정론적이지만, 결과는 불확실함\n",
    "    3. 불완전한 모델링: 관찰한 정보중 일부를 버려야 하는 모델을 사용할 때, 그 버려진 정보는 모델의 예측에서 불확실성을 야기함\n",
    "    \n",
    "p1 (page 55)\n",
    "* 많은 경우에, 간단하지만 불확실한 방법을 사용하는게 실용적임\n",
    "* ????? 좀 더 고민할필요있음\n",
    "\n",
    "p2 (page 55)\n",
    "* 확률이론이 모든 인공지능 어플리케이션의 도구가 되진 않음\n",
    "* 확률이론은 원래 사건이 일어나는 빈도를 알아내기위해 연구되었음\n",
    "* 포커게임해서 특정 카드를 뽑는 것과 같은 사건을 연구하기 위해 확률 이론이 어떻게 사용되었는지 알 수 있음\n",
    "* 이런 사건은 반복적으로 일어날 수 있는데 일어날 확률을 p라고 한다면, 반복되는 확률 p가 그 사건을 초래한다고 할 수 있음(반복적으로 카드를 뽑는 행위와 같은 동일 환경에서 일어나는 확률의 경우 가능)\n",
    "* 하지만 반복적으로 일어나지 않는 환경에서는 위와 같은 것들이 적용되기 힘듦\n",
    "* 예를 들면, 환자가 독감에 걸릴 확률이 40%라고 하지만, 환자마다 각각 환경이 다 다르기 때문에 환자 각각에게 이 이론을 적용하기에는 힘듦\n",
    "* 이 때 신뢰도를 나타내는 확률을 사용하는데, 1인 경우 의사의 판단을 절대적으로 믿는 경우, 0인 경우 의사의 판단을 절대적으로 신뢰하지 않는 경우라 할 수 있음\n",
    "* 여기서, 환자의 환경에 따라 독감에 걸리는 확률이 영향을 받기 때문에, 전 후 두 사건이 서로 연관성을 가지고, 이를 베이지안 확률이라 함\n",
    "* 정리하면, 카드를 뽑는 것과 같은 것은 환경이 동일하기 때문에 빈도확률이라 하고, 환자를 진단하는 것은 각 환자의 상태가 다르기 때문에 베이지안 확률이라 할 수 있음\n",
    "\n",
    "p3 (page 55)\n",
    "* 불확실성에 대한 상식적인 추론을 하기 위해서는 베이지안 확률을 빈도확률가 같은 방법으로 추론하는 방법이 있음\n",
    "* 예를 들어, 빈도 확률에서 특정한 카드집에서 원하는 카드를 뽑은 사건을 계산 하는 것을, 의사가 환자를 진단할때, 특정한 증상을 가지는 환자는 진단하는 사건과 동일시 할 수 있음\n",
    "\n",
    "\n",
    "p1 (page 56)\n",
    "* 확률은 불확실성을 다루기위한 논리의 확장으로 볼 수 있음\n",
    "* 이런 논리는 명제가 참이거나 거짓이라는 가정하에 어떤 명제가 참인지 거짓인지를 결정하기 위한 일련의 공식을 제공함 --> 베이지안 확률\n",
    "* 확률 이론은 다른 명체의 가능성을 고려하여 명제의 가능성을 결정하기 위한 이련의 공식을 제공해줌\n",
    "\n",
    "## 3.2 Random Variables(확률 변수)\n",
    "\n",
    "p2 (page 56)\n",
    "* 랜덤 변수는 다른 값을 무작위로 취할 수 있는 값을 의미함\n",
    "* 변수를 표현할 때 소문자영어와 영어에 스크립트 문자로 사용할수 있는 값을 나타냄\n",
    "* 예를 들어 \\\\(x_1 \\\\) \\\\(x_2 \\\\) 같이 사용됨\n",
    "* 벡터의 경우 랜덤 변수벡터는 x로 쓰고 그 안의 변수는 \\\\(x \\\\) 로 표현함\n",
    "\n",
    "p3 (page 56)\n",
    "* 랜덤 변수는 불연속 적이거나 연속적일 수 있음\n",
    "* 불연속 랜덤 변수는 유한하거나 셀 수 없이 무한한 수의 상태를 갖는 변수\n",
    "* 이 때 이 변수는 굳이 정수일 필요가 없고 일정한 수가 없는 것으로 간주할 수 있음\n",
    "\n",
    "\n",
    "## 3.3 Probability Distributions\n",
    "\n",
    "p4 (page 56)\n",
    "* 확률분포는 확률 변수이나 확률 변수의 집합이 가능한 각 상태를 취할 가능성에 대한 설명임 \n",
    "* 확률분포를 설명하기 위해서 이 변수가 이산적인지 아니면 연속적인지에 따라 방법이 달라짐\n",
    "\n",
    "### 3.3.1 Discrete Variable and Probabiltiy Mass Functions(확률질량함수)\n",
    "\n",
    "p5 (page 56)\n",
    "* 이산 변수에서의 확률분포는 Probability mass function(PMF, 확률질량함수)를 사용하셔 설명할 수 있음\n",
    "* 확률질량함수를 대문자 확률변수 P로 나타낼 수 있음\n",
    "* 확률 변수을 다른 확률질량함수에 연관지을 수 있으며 독자들은 어떤 확률질량함수가 확률 변수을 참고했는지 추측해야함\n",
    "\n",
    "\n",
    "p1 (page 57)\n",
    "* 확률질량함수는 확률 변수의 상태에서 그 상태를 취하는 확률 변수의 확률로 매핑됨\n",
    "* x = \\\\(x \\\\)인 확률을 P(\\\\(x \\\\)) 라고할 때, 1은 x = \\\\(x \\\\)가 명백한 사실일때 쓰이고, 0은 x = \\\\(x \\\\)가 불가능할 때 쓰임\n",
    "\n",
    "p2 (page 57)\n",
    "* 확률질량함수는 많은 변수에 동시에 작용할 수 있음\n",
    "* 만은 변수에 대한 이러한 확률 분포를 Joint probability distribution(결합분포)이라 함\n",
    "\n",
    "![pic01](https://user-images.githubusercontent.com/19326012/75846618-3b97f400-5e20-11ea-88a6-db082eeef5e3.PNG)\n",
    "\n",
    "\n",
    "p3 (page 57)\n",
    "* 확률 변수 x에 대한 확률질량함수가 되기 위해서는 함수 P가 다음과 같은 조건을 만족해야함\n",
    "    1. P는 x의 가능한 모든상태의 집합이여야 함\n",
    "    2. 모든 확률변수 \\\\(x \\\\)는 집합 x에 속하며 확률 밀도함수 P(x)는 0과 1사이의 수이며 불가능한 사건의 확률은 0이고 사건이 반드시 일어날 확률은 1임\n",
    "    3. 모든 확률변수의 합은 1이며 이는 정규화되는 것을 의미하기도 함, 이를 이용해서 많은 사건 중 하나의 사건이 발생할 확률을 구하거나 하나의 발생할 사건을 계산하여 하나보다 큰 확률을 얻을 수 있음\n",
    "    \n",
    "p4 (page 57)\n",
    "* 예를들어, 단일 이산 확률 변수 x가 k개의 다른 상태를 가지고 있다고 할 때, x에 대해 연속균등분포를 적용할 수 있고 이는 각각의 상태를 같은 확률로 만드는 것임, 따라서 모든 i에 대해 P(x=\\\\(x_i \\\\)) = 1/k 로 표현할 수 있음\n",
    "* 또한 이 표현은 확률 질량 함수의 조건에 충족하는 것을 볼 수 있음, 즉, \n",
    "\n",
    "![pic02](https://user-images.githubusercontent.com/19326012/75846517-f1af0e00-5e1f-11ea-9f7e-56b45d280314.PNG)\n",
    "\n",
    "![pic03](https://user-images.githubusercontent.com/19326012/75846522-f5db2b80-5e1f-11ea-8550-b0678d718fb9.PNG)\n",
    "\n",
    "\n",
    "### 3.3.2 Continuous Variables(연속확률변수)와 Probability Denstiy Functions(확률밀도함수)\n",
    "p1 (page 58)\n",
    "* 연속확률변수가 있을 때, 확률 분포를 설명하기 위해 확률 질량 함수보다는 확률 밀도 함수를 사용함\n",
    "* 확률 밀도 함수가 될려면 다음과 같은 조건이 필요함\n",
    "    1. p는 x의 가능한 모든상태의 집합이여야 함\n",
    "    2. 모든 확률변수 \\\\(x \\\\)는 집합 x에 속하며 P(x)는 0보다 크지만, 1보다도 클 수 있음\n",
    "    3. 모든 확률 변수의 합은 1임\n",
    "    \n",
    "p2 (page 58)\n",
    "* 확률 밀도 함수는 특정 상태의 확률을 나타내주진 않지만, 대신 부피를 갖는 무한 영역 내에서의 확률을 알아낼 수 있음\n",
    "    \n",
    "p3 (page 58)\n",
    "* 밀도 함수를 통합하여 실제적인 확률 질량을 찾을 수 있음\n",
    "* 특히 x가 일부 집합 S에 있는 확률은 해당 집합에 대한 P(x)의 적분에 의해 주어짐\n",
    "    \n",
    "p4 (page 58)\n",
    "* 실수 구간에 대한 균일 분포를 고려하면 특정 확률 밀도에 해당하는 확률 밀도함수의 예를 알아낼 수 있음\n",
    "* 함수 u(x;a,b)를 사용하여 이를 나타낼 수 있는데, 이 때, a와 b를 구간의 끝점이고 x는 함수의 인수임\n",
    "* 구간 밖의 확률 질량이 없도록 하기 위해 x가 구간[a,b]밖을때의 확률이 0이고, [a,b]내에 있을때의 확률이 1/b-a라 한다면 이것을 이용하여 x는 [a,b]구같에서 균일 분포를 따른 다는 것을 알 수 있음\n",
    "\n",
    "![pic05](https://user-images.githubusercontent.com/19326012/75846530-fbd10c80-5e1f-11ea-8f9d-150a8852bf49.PNG)\n",
    "\n",
    "\n",
    "## 3.2 Marginal Probability(주변 분포)\n",
    "p5 (page 58)\n",
    "* 주변 확률 분포란 부분집합에 대한 확률 분포를 뜻함\n",
    "p6 (page 58)\n",
    "* 만약 이산 확률 변수 x,y가 있다면, 그리고 그 확률을 P(x,y)라 한다면, \n",
    "\n",
    "![pic06](https://user-images.githubusercontent.com/19326012/75846536-01c6ed80-5e20-11ea-8d72-1477911d1ac6.PNG)\n",
    "p1 (page 59)\n",
    "* 즉, 모든 x에 대해서 특정 y집합의 확률을 뜻함\n",
    "* 확률을 계산할 때, 행에 x, 열에 y를 나열하여 x값을 다 더해서 각기 다른 y축에 적음\n",
    "* 즉, x의 확률은 특정 x값에 대한 y의 적분값과 같음\n",
    "\n",
    "## 3.5 Conditional Probability(조건 확률)\n",
    "p2 (page 59)\n",
    "* 많은 경우에서, 어떠한 사건의 확률에서 또 다른 사건이 일어날 확률에 대해 관심을 가짐\n",
    "* 이러한 경우를 조건 확률이라고 함\n",
    "* 이럴때, y가 y일때, 그리고 x가 x일때의 확률함수를 P(y = y | x = x)라 할 수 있음\n",
    "\n",
    "![pic07](https://user-images.githubusercontent.com/19326012/75846546-07243800-5e20-11ea-8e31-2afcafc3e656.PNG)\n",
    "\n",
    "* 조건 확률은 P(x = x) > 0일경우에만 가능함, 즉, 사건이 안일어 날 수는 없음\n",
    "* 사건이 일어나지 않은 조건확률은 계산할 수 없음\n",
    "\n",
    "p3 (page 59)\n",
    "* 조건 확률과 어떤 행위가 일어났을때를 계산하는 것과 혼동하지 않는 것이 중요함\n",
    "* 예를 들어, 독일어를 할 줄 아는 사람이 독일에서 온 확률은 높지만, 무작위로 선택된 사람이 독일어를 말하도록 가르쳐도 그들이 독일인이 되지는 않음\n",
    "\n",
    "## 3.6 The Chain Rule of Conditional Probabilities\n",
    "\n",
    "p4 (page 59)\n",
    "* 많은 확률변수에 대한 결합확률분포는 조건 분포로 나누어질 수 있음\n",
    "\n",
    "![pic08](https://user-images.githubusercontent.com/19326012/75846556-0c818280-5e20-11ea-86dc-4460050786e1.PNG)\n",
    "\n",
    "\n",
    "* 이를 연쇄 규칙 또는 곱의 확률 규칙이라고 하고, 이는 조건부 확률을 따르고 있음\n",
    "\n",
    "## 3.7 Independence and Conditional Independence(조건부 독립성)\n",
    "\n",
    "p1 (page 60)\n",
    "* 두 확률 분포가 서로 곱으로 표현 될 수 있는 경우 두 확률분포를 독립적인 관계라고 할 수 있음\n",
    "P(a, b, c) = P(a|b,c)P(b,c)\n",
    "P(b, c) = P(b|c)P(c)\n",
    "P(a, b, c) = P(a|b,c)P(b|c)P(c)\n",
    "\n",
    "p2 (page 60)\n",
    "* 또한 확률분포가 3개 이상일 경우, 만약 조건무 확률 분포가 모든 z에 대해 확률 변수 x, y가 인수분해 되면, 두 확률 변수 x, y는 조건부로 독립적이라 할 수 있음\n",
    "\n",
    "![pic09](https://user-images.githubusercontent.com/19326012/75846562-12776380-5e20-11ea-9c0f-b831d7ac23d8.PNG)\n",
    "\n",
    "\n",
    "p3 (page 60)\n",
    "* x⊥y는 x와 y가 독립적이라는 뜻이고, x⊥y|z는 x와 y가 z가 주어지면 조건적으로 독립적이라는 의미임\n",
    "\n",
    "## 3.8 Expectation, Variance and Covariance\n",
    "\n",
    "p4 (page 60)\n",
    "* 확률 분포 p(x)와 관련하여 함수 f(x)의 기댓값은 x가 P에서 추출될 때 f가 취하는 평균 또는 평균값임\n",
    "* 기댓값은 Ex[f(X)]와 같이 기대가 끝나는 이름을 넣어 쓸 수 있음\n",
    "\n",
    "p1 (page 61)\n",
    "* 기대값이 선형이라면 그리고 a와 b가 x에 독립적이지 않다면\n",
    "\n",
    "![pic12](https://user-images.githubusercontent.com/19326012/75846568-17d4ae00-5e20-11ea-9727-fedfa7dedbb5.PNG)\n",
    "\n",
    "\n",
    "p2 (page 61)\n",
    "\n",
    "* 분산은 확률 분포에서 x의 다른 값을 샘플링 할 때, 랜덤 변수 x의 함수 값이 얼마나 다른지 측정함\n",
    "* 분산의 값이 낮으면 예상값에 가까운 것이고 분산의 제곱근을 표준편차라고 함\n",
    "\n",
    "\n",
    "![pic11](https://user-images.githubusercontent.com/19326012/75846574-1c996200-5e20-11ea-95a7-0f3dc9ac24a8.PNG)\n",
    "\n",
    "p3 (page 61)\n",
    "* covariance는 두 변수가 서로 얼마나 선형적인지에 대해 나타낼 수 있으며 또한 이 두 변수의 scale에 대해서도 나타낼 수 있음\n",
    "\n",
    "![pic13](https://user-images.githubusercontent.com/19326012/75846591-21f6ac80-5e20-11ea-84fe-8c1cbb503327.PNG)\n",
    "\n",
    "* covariance이 절대값이 높으면 두 값들의 변화가 매우 많은 것을 의미하고 또한 두 값의 평균과 두 값의 차이가 크다는 것을 의미함\n",
    "* --> 공분산의 식을 보면, x의 편차와 y의 편자를 곱하여 그 값의 평균을 나타내고 있음.\n",
    "* 공분산의 값이 양수라면, 두 변수는 동시에 각각 높은 값을 가지는 경향이 있음\n",
    "* * --> 즉, 어떤 샘플 f(x)라는 특징이 x의 평균보다 크고 그샘플의 y값인 f(y)도 특징이 y의 평균보다 클 때, 공분산은 양수가 될 것이고 x가 큰 값을 가질 때, y도 큰 값을 가지는 연관성을 가짐\n",
    "* covariance의 값이 음수라면, 하나의 변수는 높은 값을 가지지만 동시에 다른 값은 상대적으로 낮은 값을 가지는 경향이 있음\n",
    "* --> 즉, x의 편차는 양수의 값을 가지지만, y의 편차가 음수의 값을 가질때 공분산은 음수를 가짐\n",
    "* correlation과 같은 것은 개별 변수의 scale에 따라 영향을 받는 것이 아니라 변수들이 얼마나 관련되어 있는지 측정하기 위해 각 변수의 기여도를 표준화함\n",
    "* --> correlation이 -1일때는 음의 방향으로 의존성이 높은 상태이며, +1이면 가장 양의 방향으로 의존성이 높은 상태임\n",
    "* --> 즉, x의 변화를 y도 얼마나 따라하느냐를 나타낸 것임(x가 증가하면 y도 증가 ....)\n",
    "\n",
    "p4 (page 61)\n",
    "* 공분산의 개념과 종속은 서로 연관성을 가지지만 서로 다른 특징을 가짐\n",
    "* 독립적인 두 변수에는 공분산이 없고, 0이 아닌 공분산이 있는 두 변수는 서로 종속적임\n",
    "* --> 독립적인 관계의 두 변수의 공분산은 0이지만, 공분산이 0인 두변수는 독립적일 수도 있고 아닐 수도 있음\n",
    "* 두 변수가 공분산이 없어 독립적이라는 의미는 두 변수가 서로 연관이 없다는 뜻이며, 공분산이 있으면 서로 연관이 있다는 의미\n",
    "* 공분산이 0을 가지는 두 변수가 있다면, 이 두 변수사이에는 선형관계가 없음, 즉, 어떠한 영향도 서로 주고받지 않음\n",
    "* 종속적인 관계인 두 변수의 공분산은 0이 아니지만 종속적이면서 0인 관계가 있음\n",
    "\n",
    "84fe-8c1cbb503327.PNG)\n",
    "![pic14](https://user-images.githubusercontent.com/19326012/75846601-2c18ab00-5e20-11ea-8261-47b8c3ce10fb.PNG)\n",
    "\n",
    "※ https://m.blog.naver.com/PostView.nhn?blogId=sw4r&logNo=221025662499&proxyReferer=https%3A%2F%2Fwww.google.com%2F\n",
    "\n",
    "* 예를 들어, y = \\\\(x^2 \\\\)인 관계가 있고 y와 x는 서로 선형이 아니기 때문이 공분산은 0임, 하지만 두 변수가 독립적이라 할 수는 없는데, 그 이유는 x가 증가할 때 y도 증가하고 x가 감소할 때, y도 감소하기 때문\n",
    "\n",
    "p1 (page 62)\n",
    "* 크기가 n인 임의의 벡터의 공분산배열은 n X n 의 배열이며 다음과 같이 나타냄 \\\\(Cob(x)_{{i},{j}} \\\\) = \\\\(Cob({x_i},{x_j}) \\\\)\n",
    "* 공분산 배열의 대각선 값들은 공분산을 의미함  \\\\(Cob(x)_{{i},{i}} \\\\) = \\\\(Cob({x_i}) \\\\)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.9 Common Probability Distributions\n",
    "p1. (62p)\n",
    "- 머신 런닝에서 여러 간단한 확률 분포가 유용하게 쓰임\n",
    "\n",
    "### 3.9.1 Bernoulli Distribution\n",
    "p1.\n",
    "- 베르누이 분포는 이진 랜덤 변수에 대한 분포\n",
    "- 이 분포는 매개변수 ${\\phi \\in[0.1]}$ 에 의해 결정되고 ${\\phi}$는 랜덤 변수의 확률이 1에 가깝게 함\n",
    "- ${\\phi}$는 다음과 같은 특성을 가심\n",
    "\n",
    "$${P(x=1)=\\phi}$$\n",
    "$${P(x=0)=1-\\phi}$$\n",
    "$${P(x=X)=\\phi ^x(1-\\phi)^(1-x)}$$\n",
    "$${E_x[x]=\\phi}$$\n",
    "$${Var_x(x)=\\phi (1-\\phi)}$$\n",
    "\n",
    "\n",
    "### 3.9.2 Multinoulli DIstribution\n",
    "p1.\n",
    "- Multinoulli 또는 Categorical 분포라고 불리는 이 분포는 유한한 서로 다른 k개의 상태에 따른 이산 변수의 분포\n",
    "- Multinoulli 분포는 벡터 ${p \\in [0,1]^{k-1}}$에 의해 파라미터화 되는데 ${p_i}$는 i 번째 상태의 확률을 의미\n",
    "- 마지막 k 번째 상태의 확률은 ${1-1^Tp}$로 주어짐 (이 때의 제약사항: ${1^Tp<=1}$)\n",
    "- Multinoulli 분포는 대상의 여러 'categories'에 대한 분포를 언급할 때 사용되어 주로 상태 1이 수치 1을 가진다고 가정하지 않음\n",
    "- 그렇기 때문에 multinoulli하게 분포하는 랜덤 변수들의 예측이나 분산을 계산할 필요 없음\n",
    "\n",
    "p2. (63p)\n",
    "- 베르누이, multinoulli 분포는 이 도메인에서의 어떠한 분포라도 표현하기 적절\n",
    "- 모든 변수를 열거하기 위해 이산적 변수를 모델링하여 강력하지만 오히려 도메인이 단순하기 때문에 도메인의 어떠한 분포라도 충분히 설명할 수 없음\n",
    "- 연속적인 변수들을 다룰 때 셀 수 없이 많은 상태가 도출되고 작은 수의 파라미터로 표현되는 분포는 정밀한 제약을 두어야함\n",
    "\n",
    "### 3.9.3 Gaussian Distribution\n",
    "p1.\n",
    "- 실수 체계에서 가장 널리 쓰이는 분포는 정규 분포 (normal distribution)으로 가우시안(Gaussian) 분포로도 알려짐\n",
    "\n",
    "$${\\begin{equation*}N(x:\\mu,\\sigma^2)=\\sqrt{\\frac{1}{2 \\pi \\sigma^2}}exp(\\frac{-1}{2 \\sigma ^2}(x- \\mu)^2)\\end{equation*}}$$\n",
    "\n",
    "- 밀도 함수를 나타내는 Figure 3.1\n",
    "\n",
    "\n",
    "![image1](https://user-images.githubusercontent.com/19326012/75846659-59655900-5e20-11ea-9d82-9ae92e90d7f5.PNG)\n",
    "\n",
    "\n",
    "\n",
    "p2.\n",
    "- 두 파라미터 ${\\mu \\in R}$, ${\\sigma \\in (0, \\infty)}$에 따라 정규 분포 생성\n",
    "- ${\\mu}$는 곡선의 최고점이자 평균을 의미 ${E[x]=\\mu}$\n",
    "- ${\\sigma}$는 분포의 표준편차로 분산은 ${\\sigma^2}$으로 표현\n",
    "\n",
    "p3.\n",
    "- 확률 분포 함수를 평가할 때 ${\\sigma}$를 제곱하고 역수를 취함\n",
    "- 다른 파라미터 값들로 자주 활률 분포 함수를 평가할 때 분포를 파라미터(모형)화하는 더 효율적인 방법을 파라미터 ${\\beta \\in (o, \\infty)}$를 이용하여 분포의 '정확도' 또는 역분산을 나타냄\n",
    "\n",
    "$${N(x:\\mu,\\beta^{-1})=\\sqrt{\\frac{\\beta}{2 \\pi}}exp(-\\frac{1}{2}\\beta(x- \\mu)^2)}$$\n",
    "\n",
    "\n",
    "\n",
    "p4. (64p)\n",
    "- 정규 분포는 많은 응용에 실용적\n",
    "- 실수가 취해야하는 분포의 모양에 대한 사전 지식이 없을 경우 정규 분포는 두 가지 이유에서 좋은 디폴트가 됨\n",
    "1. 모델링하고자 하는 많은 분포들은 정규분포에 엄밀히 가까움\n",
    "    - 중심극한 정리는 많은 독립적 랜덤 변수들의 합이 정규 분포에 근사되는 것을 보여줌\n",
    "    - 즉, 실제로 사용할 때 많은 복잡한 시스템들이 더 심화된 구조의 여러 부분으로 분해되더라도 성공적으로 정규 분포화된 노이즈로 모델링됨\n",
    "2. 같은 분산을 갖는 모든 가능한 확률 분포들에서 정규 분포는 실수에 전반적으로 uncertainty의 최대값을 encode함\n",
    "    - 즉 정규 분포는 모델에 사전 지식을 최소한으로 삽입한다고 생각할 수 있음\n",
    "    - 이 기법을 완전히 개발하고 정당화하기 위해선 많은 수학적 기법이 요구되고 19.4.2장 까지 미룸\n",
    "\n",
    "p5. \n",
    "- 정규 분포는 ${R^n}$에 일반적으로 속하고 이 경우 '다변수 정규 분포'라 함\n",
    "- 이 분포는 양의 값을 갖는 정방향 행렬 ${\\Sigma}$로 파라미터화될 수 있음\n",
    "\n",
    "$${N(x;\\mu,\\Sigma)=\\sqrt{\\frac{1}{(2\\pi)^n det(\\Sigma)}}exp(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu))}$$\n",
    "\n",
    "\n",
    "p6. (65p)\n",
    "- 파라미터 ${\\mu}$는 여전히 분포의 평균이고 벡터 값\n",
    "- 파라미터 ${\\Sigma}$는 분포의 분산 행렬\n",
    "- 다변수의 경우이므로 PDF를 다른 값들의 파라미터에 대해 평가할 때 분산은 ${\\Sigma}$를 역수 취해야하기 때문에 계산적으로 분포를 파라미터화 하는데 효율적이지 못함\n",
    "- 대신 '정확도 행렬 (precision matrix)' ${\\beta}$를 사용\n",
    "\n",
    "$${N(x;\\mu,\\beta^{-1})=\\sqrt{\\frac{det(\\beta)}{(2\\pi)^n}}exp(-\\frac{1}{2}(x-\\mu)^T\\beta(x-\\mu))}$$\n",
    "\n",
    "p7.\n",
    "- 종종 분산 행렬을 대각 행렬로 바꾸기도 함\n",
    "- 더 간단한 방법으로는 방향에 상관없는 성질의 등방성 가우시안 분포로 분산 행렬은 identity 행렬에 스칼라 곱임\n",
    "\n",
    "\n",
    "### 3.9.4 Exponential and Laplace Distributions\n",
    "p1.\n",
    "- 딥 러닝의 맥락에서 ${x=0}$에서 첨점을 갖는 확률 분포를 구해야 함\n",
    "- 이 때 지수(Exponential) 분포를 사용\n",
    "\n",
    "$${p(x;\\lambda)=\\lambda1_{x>=0}exp(-\\lambda x)}$$\n",
    "\n",
    "- 지수 분포는 특성 함수(indicator function) ${1_{x>=0}}$을 사용하여 확률 zero를 모든 음의 값 ${x}$에 부여\n",
    "\n",
    "p2.\n",
    "- 확률 질량의 첨점을 무작위 점 ${\\mu}$에 지정할 수 있게 하는 확률 분포를 '라플라스(Laplace) 분포'라 함\n",
    "\n",
    "$${Laplace(x;\\mu,\\gamma)=\\frac{1}{2\\gamma}exp(-\\frac{|x-\\mu|}{\\gamma})}$$\n",
    "\n",
    "### 3.9.5 The Dirac Distribution and Empirical DIstribution\n",
    "p1.\n",
    "- 어떤 경우엔 확률 분포의 질량이 한 점 주위로 클러스터하는 것을 구체적으로 명시해야함\n",
    "- 이 경우, PDF를 Dirac delta 함수 ${\\delta(x)}$로 정의\n",
    "\n",
    "$${p(x)=\\delta(x-\\mu)}$$\n",
    "\n",
    "- Dirac delta 함수는 0을 제외한모든  부분에서 0의 값을 갖지만 1로 통합됨\n",
    "- Dirac delta 함수는 각 ${x}$값을 실수화된 결과와 결합하는 일반 함수가 아니며 '일반화된 함수'라는 다른 수학적 표현으로 통합되었을 때 함수의 특성에 따라 정의됨\n",
    "- Dirac delta 함수는 각 점에 0이 아닌 매우 작은 수를 입력하는 일련의 함수의 limit point라 할 수 있음\n",
    "\n",
    "p2. (66p)\n",
    "- ${p(x)}$를 ${-\\mu}$로부터 변환된 ${\\delta}$로 정의함으로써 ${x=\\mu}$에서 무한히 좁고 무한히 높은 확률 질량의 peak 점을 얻을 수 있음\n",
    "\n",
    "p3\n",
    "- 일반적으로 Dirac delta 분포는 'empirical(경험적) 분포'의 구성요소로 사용\n",
    "\n",
    "$${\\hat{p}(x)=\\frac{1}{m}\\left(\\sum_{i=1}^m \\delta(x-x^{(i)} \\right)^2}$$\n",
    "\n",
    "- 확률 질량 ${\\frac{1}{m}}$을 각 ${m}$ 포인트 ${x^{(1)},...,x^{(m)}}$에 대입하여 샘플의 주어진 데이터셋 생성\n",
    "- Dirac delta 함수는 연속적인 변수들에 대한 경험적 분포를 정의하기 위해서만 필요\n",
    "- 이산 변수에 대해선 문제가 더 간단\n",
    "    - 경험적 분포는 단순히 학습 셋 값의 '경험적 빈도'와 동일한 각 각능한 입력 값 확률을 통해 multinoulli 분포로 개념화될 수 있음\n",
    "\n",
    "p4.\n",
    "- 학습 예시의 데이터셋에서 형성된 경험적 분포를 모델을 데이터셋에 학습시킬 때 얻을 수 있는 sample 분포를 명시한 것이라 할 수 있음(section 5.5)\n",
    "\n",
    "\n",
    "### 3.9.6 Mixtures of Distributions\n",
    "p1.\n",
    "- 더 단순한 확률 분포들을 결합하여 확률 분포를 정의하는 것은 매우 일반적\n",
    "- 'mixture distribution'을 만드는 것\n",
    "- multinoulli 분포로부터 구성 요소 identity를 sampling 함으로써 어떤 구성 요소 분포가 sample을 생성할 것인지를 결정함\n",
    "\n",
    "$${P(x)= \\sum_{i}P(c=i)P(x|c=i)}$$\n",
    "\n",
    "- ${P(c)}$는 multinoulli 분포로 구성 요소 identities에 대한 분포\n",
    "\n",
    "p2.\n",
    "- 위 내용은 혼합 분포의 예시: 실제 값 변수들에 대한 경험적 분포는 각각의 학습 예시에 대한 하나의 Dirac 구성 요소와의 혼합 분포\n",
    "\n",
    "p3. (67p)\n",
    "- 혼합 모델은 더 풍부한 분포를 생성하기 위한 확률 분포들을 결합하는 간단한 기법\n",
    "- 16장에서 더 자세하게 간단한 분포들로부터 복잡한 확률 분포들을 생성하는 기법을 살펴볼 것\n",
    "\n",
    "p4.\n",
    "- 혼합 모델은 후에 나올 가장 중요한 개념인 '잠재(latent) 변수'에 대해 짧게 소개\n",
    "- latent variable은 직접적으로 관찰할 수 없는 랜덤 변수\n",
    "- 모델의 구성 요소 identity 변수 c는 example을 제공\n",
    "- latent variable은 결합 분포를 통한 x와 연관이 있을 것 (${P(x,c)=P(x|c)P(c)}$)\n",
    "- latent variable과 latent variable과 visible variable을 연관시키는 분포 ${P(x|c)}$에 대한 분포 ${P(c)}$는 latent variable에 대한 기준 없이 ${P(x)}$를 묘사할 수 있더라도 분포 ${P(x)}$의 모양을 결정\n",
    "- 잠재 변수는 16.5장에서 다뤄짐\n",
    "\n",
    "p5.\n",
    "- 매우 강력하고 흔히 쓰이는 혼합 모델은 '가우시안 혼합'모델로 구성 요소 ${p(x|c=i)}$는 모두 가우시간\n",
    "- 각 구성 요소는 각각 파라미터된 평균 ${\\mu^{(i)}}$, 분산 ${\\Sigma^{(i)}}$를 가짐\n",
    "- 몇 혼합은 더 많은 제약 사항이 있을 수 있음\n",
    "    - 각 분산은 제약 사항 ${\\Sigma^{(i)}=\\Sigma,\\forall{i}}$을 통해 공유될 수 있음\n",
    "- 하나의 가우시안 분포로 가우시안의 혼합은 각 구성 요소의 분산 행렬이 대각이나 등방성이 되게 제약할 수 있음\n",
    "\n",
    "p6.\n",
    "- 평균과 분산에 더해서 가우시안 혼합의 파라미터는 각 구성 요소 i에 대한 '사전 확률' ${\\alpha_i=P(c=i)}$를 명시\n",
    "- \"사전\"라는 용어는 c에 대해 x를 측정하기 '전' 모델의 믿음을 나타냄\n",
    "- 이와 비교하여 '사후 확률' ${P(c|x)}$는 x 측정 '후'에 계산됨\n",
    "- 가우스 혼합 모델은 충분한 성분을 가진 가우스 혼합 모델에 의해 임의의 0이 아닌 특정 오차로 smooth 밀도를 근사화 할 수 있다는 점에서 밀도의 '보편 근사법'임\n",
    "\n",
    "\n",
    "p7. figure 3.2 (68p)은 가우시안 혼합 모델오 부터의 samples을 보여줌\n",
    "\n",
    "\n",
    "![image2](https://user-images.githubusercontent.com/19326012/75846673-62eec100-5e20-11ea-96c9-a22d8ec97679.PNG)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 3.10 Useful Properties of Common FUnctions\n",
    "p1.\n",
    "- 특정 함수들은 확률 분포를 다룰 때 자주 등장하는데 특히 딥러닝에서 사용되는 확률 분포 함수 중 하나인 'logistic sigmoid':\n",
    "\n",
    "$${\\sigma(x)=\\frac{1}{1=exp(-x)}}$$\n",
    "\n",
    "- logistic sigmoid는 베르누이 분포의 ${\\phi}$ 파라미터를 생성하기 위해 주로 사용되는데 파라미터 ${\\phi}$ 값의 유효한 범위안에 있는 (0,1) 사이의 값을 가지기 때문\n",
    "- figure 3.3 (69p) sigmoid function 그래프\n",
    "\n",
    "![image3](https://user-images.githubusercontent.com/19326012/75846683-6aae6580-5e20-11ea-9837-d3c9cf0e8c03.PNG)\n",
    "\n",
    "\n",
    "\n",
    "- sigmoid function은 함수의 전달인자가 매우 양수에 가깝거나 음수에 가까울 때 포화되는데 이는 함수가 매우 flat 해지고 입력의 작은 변화들에 insensitive 해지는 것을 의미\n",
    "\n",
    "p2.\n",
    "- 또다른 자주 쓰이는 함수는 'softplus'함수로\n",
    "\n",
    "$${\\zeta(x)=log(1+exp(x))}$$\n",
    "\n",
    "- softplus 함수는 정규분포의 범위가 ${(0,\\infty)}$이기 때문에 파라미터 ${\\beta}$나 ${\\sigma}$를 생성시키는데 유용\n",
    "- 이 함수는 sigmoids를 포함하는 식을 잘 처리해야 할 때도 자주 쓰임\n",
    "- softplus 함수의 이름은 다음 식의 smoothed 또는 'softed' 버전에서 유래\n",
    "\n",
    "$${x^+=max(0,x)}$$\n",
    "\n",
    "- figure 3.4 (69p) softplus 함수 그래프\n",
    "\n",
    "![image4](https://user-images.githubusercontent.com/19326012/75846694-700bb000-5e20-11ea-873b-66bcd7b612c5.PNG)\n",
    "\n",
    "\n",
    "p3. (70p)\n",
    "- 다음의 특성들은 충분히 기억할 만할 것\n",
    "\n",
    "$${\\sigma(x)=\\frac{exp(x)}{exp(x)+exp(0)}}$$\n",
    "$${\\frac{d}{dx}\\sigma(x)=\\sigma(x)(1-\\sigma(x))}$$\n",
    "$${1-\\sigma(x)=\\sigma(-x)}$$\n",
    "$${log\\sigma(x)=-\\zeta(-x)}$$\n",
    "$${\\frac{d}{dx}\\zeta(x)=\\sigma(x)}$$\n",
    "$${\\forall{x}\\in(0,1), \\sigma^{-1}(x)=log(\\frac{x}{1-x})}$$\n",
    "$${\\forall{x}>0, \\zeta^{-1}(x)=log(exp(x)-1)}$$\n",
    "$${\\zeta(x)=\\int_{-\\infty}^x\\sigma(y)dy}$$\n",
    "$${\\zeta(x)-\\zeta(-x)=x}$$\n",
    "\n",
    "- 함수 ${\\sigma^{-1}|$는 통계학에서 'logit'이라 불리는데 머신 러닝에서 이 용어는 잘 쓰이지 않음\n",
    "\n",
    "p4.\n",
    "- 식 ${\\zeta(x)-\\zeta(-x)=x}$은 이름 \"softplus\"에 대한 추가적 타당성을 제시\n",
    "- softplus 함수는 수식 ${x^+=max(0,x)}$, '양수 부분'의 smoothed 버전\n",
    "- 양의 부분 함수는 '음의 부분' 함수, ${x^-=max(0,-x)}$와 반대됨\n",
    "- 음의 부분과 동일한 smooth 함수를 얻기 위해서 ${\\zeta(-x)}$를 사용\n",
    "- x는 양과 음의 부분에서부터 identity ${x^+-x^-=x}$를 통해 복구될 수 있기 때문에 같은 관계인 ${\\zeta(x)|$와 ${\\zeta(-x)}$를 이용하여 x 복구 가능, figure 3.4 (69p)\n",
    "\n",
    "![image4](https://user-images.githubusercontent.com/19326012/75846694-700bb000-5e20-11ea-873b-66bcd7b612c5.PNG)\n",
    "\n",
    "\n",
    "## 3.11 Bayes' Rule\n",
    "p1.\n",
    "- 종종 ${P(y|x)}$는 아는데 ${P(y|x)}$를 알아야하는 상황이 발생\n",
    "- 다행히도 ${P(x)}$또한 알고 있을 때 'Bayes' rule'을 적용하여 원하는 양을 계싼할 수 있음\n",
    "\n",
    "$${P(x|y)=\\frac{P(x)P(y|x)}{P(y)}}$$\n",
    "\n",
    "- ${P(y)}$가 식에 나타나지만 주로 ${P(y)=\\Sigma_{x}P(y|x)P(x)}$를 계산하는데 쓰여 P(y)의 지식에서부터 시작할 필요 없음\n",
    "\n",
    "p2. (71p)\n",
    "- Baye's rule은 조건 확률의 정의로부터 도출하기 간단하지만 많은 텍스트들이 언급했기 때문에 이 식의 이름을 아는 것이 필요\n",
    "- 이 식의 이름은 Reverned Thomas Bayes로 이 수식의 특별한 경우를 처음으로 발견한 사람의 이름임\n",
    "- 위에 명시된 일반적인 버전은 Pierre-Simon Laplace가 독자적으로 개발함\n",
    "\n",
    "## 3.12 Technical Details of Continuous Variables\n",
    "p1.\n",
    "- 연속적인 랜덤 변수들과 확률 밀도 함수들의 적절한 공식 이해를 위해 'measure theory'라고 알려진 수학의 한 분기로 확률 이론 개발이 필요\n",
    "- measure theory는 이 책의 범위를 벗어나지만 간단히 measure theory가 사용된 문제들을 간단하게 그릴 수 있음\n",
    "\n",
    "p2.\n",
    "- 3.3.2장에서 집합 ${S}$의 연속적인 벡터값 x의 확률은 집합 ${S}$에 대한 ${p(x)}$의 적분으로 주어짐\n",
    "- 집합 ${S}$의 몇 가지 선택은 역설을 불러올 수 있음\n",
    "    - ${p(x \\in S_1)+p(x \\in S_2)>1}$, ${S_1\\cap S_2=0}$을 만족하는 두 집합 ${S_1, S_2}$를 생성할 수 있음\n",
    "    - 예를 들어, fractal모양의 집합이나 유리수 집합을 변형시킴으로써 정의되는 집합을 만듦으로써 이 두 집합은 일반적으로 실수의 무한한 정확성의 heavy use를 일으키면서 생성됨\n",
    "- measure theory의 핵심 contributions 중 하나는 역설을 마주치지 않는 확률을 계산할 수 있는 집합들의 집합 특징을 제공하는 것임\n",
    "- 본 책은 상대적으로 단순한 서술로 집합들을 통합만 하여 이런 관점에서의 measure theory는 관련있는 문제가 되지 않을 것임\n",
    "    \n",
    "p3.\n",
    "- 원래 목적을 위해 measure theory는 ${R^n}$집합의 대부분의 점들에 적용되는 이론들을 묘사하는데 더 유용하지만 몇 corner case(정상 범위 외에서만 발생하는 문제)에는 적용하면 안됨\n",
    "- measure theory는 점들의 집합이 무시할만큼 작다는 것을 설명하는 철저한 방법을 제공\n",
    "- 그러한 집합은 'measure zero'를 가짐\n",
    "- 이 개념을 다루진 않겠음\n",
    "- 이 책에서 다루고자 하는 영역에서 measure zero는 측정하고자 하는 공간에서 어떠한 부피도 차지하지 않는 다는 직관만 있으면 이해하는데 충분\n",
    "    - 예를 들어, ${R^2}$에서 한 선이 measure zero를 가지는데 반면 채워진 다각형은 positive measure을 가짐\n",
    "    - 비슷하게, 각 점은 measure zero를 가짐\n",
    "- 각각 measure zero를 갖는 셀 수 있는 많은 집합체 또한 measure zero를 가짐 (그러므로 모든 유리수 집합도 measure zero를 가짐)\n",
    "\n",
    "p4.\n",
    "- 또다른 measure theory의 유요한 용어는 'almost everywhere'\n",
    "- almost everywhere을 갖는 특성은 measure zero의 집합을 제외한 모든 공간에서 유지됨\n",
    "- 왜냐하면 이 예외사항들은 무시해도 될 정도의 공간을 차지하기 때문에 많은 응용들에서 무시될 수 있음\n",
    "- 몇 중요한 확률 이론 결과들은 모든 이산 값에 대해 유지되지만 연속적인 값들에 대해서는 \"almost everywhere\"만 적용됨\n",
    "\n",
    "p5.\n",
    "- 연속 변수들의 또 다른 기술적 detail은 연속 랜덤 변수들을 다루는 것과 연관되는데 이는 서로의 결정론적 함수\n",
    "- 두 랜덤 변수 x, y를 가정했을 때 ${y=g(x)}$의 관계로 함수 ${g}$는 역수를 취할 수 있으며 연속적이고 미분가능한 변환임\n",
    "- ${p_y(y)=p_x(g^{-1}(y))}$를 기대할 수도 있지만 이건 다루는 범위가 아님\n",
    "\n",
    "p6.\n",
    "- 간단한 예시로, 스칼라 랜덤 변수 x, y가 있다고 가정\n",
    "- ${y=\\frac{x}{2}}$, ${x~U(),1)}$\n",
    "- ${p_y(y)=p_x(2y)}$법칙을 사용하면 ${p_y}$는 1이 되는 범위 ${[0,\\frac{1}{2}]}$를 제외한 모든 범위에서 0이 될 것임\n",
    "- 이는 수식으로\n",
    "\n",
    "$${\\int{p_y(y)dy}=\\frac{1}{2}}$$\n",
    "\n",
    "- 이는 확률 분포의 정의를 위반하는 자주 있는 실수\n",
    "- 이러한 접근의 문제점은 함수${g}$에 의한 공간 왜곡을 염두에 두지 않은 접근임\n",
    "- x의 확률이 무한소로 작아지는 구간에서 질량 ${\\delta x}$는 ${p(x)\\delta x}$에 의해 주어짐\n",
    "- g는 공간을 확대 및 축소할 수 있기 때문에 x 공간에서 x 주변의 무한소 질량은 y 공간의 다른 질량을 가질 것\n",
    "\n",
    "\n",
    "p7.\n",
    "- 문제 해결을 위해 스칼라 경우로 돌아감\n",
    "- 다음과 같은 성질을 만족해야함\n",
    "\n",
    "$${|p_y(g(x))dy|=|p_x(x)dx|}$$\n",
    "\n",
    "- 수식을 정리하면\n",
    "\n",
    "$${p_y(y)=p_x(g^{-1}(y))|\\frac{\\partial x}{\\partial y}|}$$\n",
    "\n",
    "- 또는 동등하게\n",
    "\n",
    "$${p_x(x)=p_y(g(x))|\\frac{\\partial g(x)}{\\partial x}|}$$\n",
    "\n",
    "- 높은 차원에서 이 편미분이 '자코비안 행렬'의 결정자를 생성-${J_{i,j}=\\frac{\\partial x_i}{\\partial y_i}}$\n",
    "- 즉 실제 값 x, y는\n",
    "\n",
    "$${p_x(x)=p_y(g(x))|det(\\frac{\\partial g(x)}{\\partial x})|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.13 Information Theory\n",
    "p1 (**page73**):\n",
    "+ 신호에 얼마나 많은 정보가 있는지 정량화 하는 수학 분야\n",
    "+ 원래는 통신 잡음이 많은 무선 통신에서 이산 알파벳 메시지를 보내는 것을 연구하기 위해 만들어짐\n",
    "+ 다양한 인코딩 체계를 사용하여 특정 확률 분포에서 샘플링 된 메시지의 예상 길이를 계산하는 방법\n",
    "\n",
    "p2:\n",
    "+ 정보 이론의 기본은 \"일어날 수없는 사건\"이 발생했다는 것을 배우는 것이 \"당연한 사건\"이 발생했다는 것을 배우는 것보다 더 유익하다는 것이다.\n",
    "+ 예를 들어, \"오늘 아침 해가 뜬다\" 라는 메시지는 보낼 필요가 없을 정도로 유익하지 않지만\"오늘 아침 일식이 있었다\"는 메시지는 매우 유익하다.\n",
    "\n",
    "p3:\n",
    "+ 정보이론은 이러한 직관적인 것을 공식화하는 방식으로 정보를 정량화 하고자 한다.\n",
    "+ 1. 당연하게 발생하는 이벤트는 적은 정보를 지녀야 하며, 너무나 당연한 정보는 포함되지 말아야 한다.\n",
    "+ 2. 드물게 발생하는 이벤트는 더 귀한 정보를 가진다.\n",
    "+ 3. 독립적인 이벤트는 추가정보가 있어야 한다.\n",
    "\n",
    "p4:\n",
    "+ 이러한 세 가지 조건을 만족시키기 위해 이벤트 확률변수 $x$의 값이$\\mathrm{x}$인 정보량을 다음과 같이 표현한다.\n",
    "$$I\\left( x \\right) =-\\log { P(x) }$$\n",
    "+ 여기서 로그는 밑이 $e$ 인 자연로그 이며, 단위는 nat 라고 부른다.\n",
    "+ 1 nats은 확률 $1/e$를 관찰함으로써 얻은 정보의 양을 나타낸다.\n",
    "+ 만약, 로그의 밑이 2 인 경우에 그 정보량의 단위는 섀년(Shannon) 또는 비트(bit) 라고 부른다.\n",
    "\n",
    "p1 (**page74**):\n",
    "+ 이산적으로 발생하는 이벤트는 일부 정보 손실이 있을 수 있다.\n",
    "+ 예를 들어, (추가 정리 예정)\n",
    "\n",
    "p2:\n",
    "+ 섀넌 엔트로피(Shannon entropy)는 해당 분포에서 도출 된 이벤트에서 예상되는 정보량을 뜻 한다.\n",
    "+ 전체 사건의 확률분포의 불확실성의 양을 나타낼 때 사용된다.\n",
    "+ 어떤 확률분포 $P$에 대한 섀넌 엔트로피 :\n",
    "\n",
    "$$H\\left( P \\right) =H\\left( x\\right) ={ E }_{ X\\sim P }\\left[ I\\left( x \\right)  \\right] ={ E }_{ X\\sim P }\\left[ -\\log { P(x) }  \\right]$$\n",
    "\n",
    "+ 섀년 엔트로피는 발생 가능한 모든 결과의 가지 수에 밑이 2인 로그를 취한 것과 같다.\n",
    "+ 앞, 뒤 면이 다른 동전 뒤집기 처럼 동등한 확률을 가진 1/2인 경우는 높은 엔트로피를 가지며, 앞면이 두 개인 동전 뒤집기의 경우는 앞면만 나올 확률이 자명하기 때문에 엔트로피가 낮다. (사실상 0임)\n",
    "\n",
    "p3:\n",
    "+ 서로 다른 데이터의 분포 $P(x)$와 $Q(x)$가 있는 경우 쿨백-라이블러 발산(Kullback-Leibler divergence, KLD, KL 발산)을 이용해 두 분포가 얼마나 다른지 측정할 수 있다.\n",
    "\n",
    "$${ D }_{ KL }\\left( P||Q \\right) =\\mathbb{ E }_{ x\\sim P }\\left[ \\log { \\frac { P\\left( x \\right)  }{ Q(x) }  }  \\right]=\\mathbb{ E }_{ x\\sim P }\\left[ -\\log { \\frac { Q\\left( x \\right)  }{ P(x) }  }  \\right]$$\n",
    "\n",
    "p4:\n",
    "+ 불연속 변수의 경우, 확률 분포 $Q$에서 도출 된 메시지 길이를 최소화할 때, 확률 분포 $P$에서 가져온 기호를 포함하는 메시지를 보내는 데 필요한 추가 정보입니다.\n",
    "\n",
    "p5:\n",
    "+ $P$ 와 $Q$가 동일한 확률분포일 경우 KLD는 정의에 따라 그 값이 0이 된다. \n",
    "+ 또한, KLD는 비대칭으로 $P$와 $Q$ 위치가 뒤바뀌면 KLD 값도 달라지며, 따라서 KLD는 거리함수로는 사용할 수 없다.\n",
    "\n",
    "p1 (**page75**):\n",
    "+ 이산변수에 대한 크로스 엔트로피는 다음과 같이 정의된다.\n",
    "\n",
    "$$H\\left( P,Q \\right) ={ E }_{ X\\sim P }\\left[ -\\log { Q(x) }  \\right]$$\n",
    "\n",
    "p2:\n",
    "+ $Q$에 대한 크로스 엔트로피를 최소화 하는 것은 다른 항에 영향을 미치지 않기 때문에 쿨백-라이블러 발산을 최소화 하는 것과 같다. \n",
    "\n",
    "p3:\n",
    "+ 종종 $\\log_{0}{0}$과 같은 표현이 나오는데, 일반적으로 정보이론에서는 이러한 표현은 $\\lim_{x \\to 0}{x}\\log{x}$ 로 표현된다.\n",
    "\n",
    "\n",
    "## 3.14 Structured Probabilistic Models\n",
    "\n",
    "p4:\n",
    "+ 기계학습 알고리즘은 많은 랜덤변수에 대한 확률 분포 표현을 이용한다.\n",
    "+ 단일 확률 분포를 사용하기에는 변수들의 관계를 나타내기 힘들다.\n",
    "\n",
    "p1 (**page77**):\n",
    "+ 단일 확률 분포를 사용하는 것 대신 확률 분포를 여러 factor로 나눈다\n",
    "+ 예를 들어,  a가 b의 값에 영향을 미치고 b의 값이 c의 값에 영향을 미치지만 a와 c가 b에 대해 독립적이라고 가정하면, 다음과 같이 나타내 수 있다.\n",
    "\n",
    "$$p(a, b, c) = p(a)p(b|a)p(c|b)$$\n",
    "\n",
    "p2:\n",
    "+ 이러한 분해는 확률 분포를 묘사하는데 필요한 매개변수의 수를 크게 줄일 수 있다.\n",
    "+ 더 적은 변수로 이러한 분해가 가능하면 확률 분포를 나타내는 비용이 줄어든다.\n",
    "\n",
    "p3:\n",
    "+ 이러한 분해는 그래프로 그려질 수 있으며, 우린 이 것을 구조화된 확률 모델(structured probabilistic model) 또는 그래프 모델(graphical model)이라 부른다.\n",
    "\n",
    "p4:\n",
    "+ 그래프 모델은 Directed Graphical Model와 Undirected Graphical Model 으로 나뉜다.\n",
    "\n",
    "p5:\n",
    "+ Directed Graphical Model은 순서가 지정되며, 화살표로 표시된다. (계층적 구조로 볼 수 있음)\n",
    "+ 각 노드는 곱 연산으로 이루어지며, $i$ 번째 까지의 분포 $p$는 다음과 같이 표기된다.\n",
    "\n",
    "$$p(x) = \\prod_{i} p(x_i|Pa_{\\mathcal{G}}(x_i))$$\n",
    "\n",
    "+ 이러한 형태의 그래프를 베이지안 네트워크라 부른며, 예시는 다음과 같다.\n",
    "![LSGfig_3_1](https://user-images.githubusercontent.com/52661707/75842528-dc33e700-5e13-11ea-8b63-822d0cc18d70.PNG)\n",
    "\n",
    "p1 (**page78**):\n",
    "+ Undirected Graphical Model은 화살표가 없는 그래프를 사용하여 분포를 나타낸다.\n",
    "+ directed와 다르게 순환 종속성을 나타낼 순 있지만, 유도 종속성은 나타낼 수 없다.\n",
    "> + Clique : 그래프 상 완벽한 부분\n",
    "> + 완벽한 부분 : 모든 노드들이 연결 되어 있는 경우\n",
    "> + 예시\n",
    "![LSGadd_3_](https://user-images.githubusercontent.com/52661707/75844529-a2fe7580-5e19-11ea-8ba3-e0cf7cdad05f.PNG)\n",
    "+ 하나의 Clique를 $\\mathcal{C}$라고 나타내자.\n",
    "+ $i$ 번째 \\mathcal{C}의 누적 분포 함수를 $\\phi^{(i)}(\\mathcal{C}^{(i)})$ 라고 할 수 있다.\n",
    "\n",
    "p2:\n",
    "+ 랜덤 변수 구성 확률은 모든 누적 분포 함수의 곱으로 나타내진다.\n",
    "+ 이 곱의 합이 1이라는 보장이 없기 때문에 정규화 상수 $Z$로 나누어야 한다.\n",
    "+ 즉, 다음과 같은 식이 도출된다.\n",
    "\n",
    "$$p(x) = \\frac{1}{Z} \\prod_{i} \\phi^{(i)}(\\mathcal{C}^{(i)})$$\n",
    "\n",
    "+ 이러한 형태의 그래프를 마르코프 랜덤 필드라 부르며, 예시는 다음과 같다.\n",
    "![LSGfig_3_2](https://user-images.githubusercontent.com/52661707/75845343-23be7100-5e1c-11ea-8d82-6b9a6211a7af.PNG)\n",
    "\n",
    "p1 (**page79**):\n",
    "+ 3장에 나온 확률 모델들을 이해 한다면, 이 책을 보는데 어려움은 없을\n",
    "\n",
    "p2:\n",
    "+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
