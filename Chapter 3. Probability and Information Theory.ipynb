{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability and Information Theory\n",
    "\n",
    "p1(**page 53**) :\n",
    "* 이 챕처에서는 probability theory와 imformation theory에 대해 설명함\n",
    "\n",
    "p2 :\n",
    "* Probability theory는 불확실한(uncertain) statements를 표현(represent)하기 위한 수학적인 프레임워크임\n",
    "* Probability theory는 새로운 불확실한 statements를 도출하기 위한 공리(axioms)와 불확실성을 정량화하는 수단을 제공함\n",
    "* 인공지능 분야에서는 다음의 2가지 주요 이유로 probability theory를 사용함\n",
    "    * Probability theory는 AI시스템이 어떻게 추론하는지 알려줌\n",
    "        - 따라서 Probability theory를 이용해서 도출된 다양한 표현식을 계산하거나 근사하도록 알고리즘을 설계함\n",
    "    * 제안된 AI시스템의 동작을 이론적으로 분석하기 위한 확률(probability)과 통계(statistics)로써 사용할 수 있음\n",
    "\n",
    "p3 :\n",
    "* Probability theory는 많은 과학 및 공학 분야에서의 기본 도구(fundamental tool)임\n",
    "\n",
    "p4 :\n",
    "* Probability theory : 불확실성이 존재할 때, uncertain statements와 reason을 만들 수 있도록 함\n",
    "* Information theory : probability distribution에서의 불확실성의 양을 정량화할 수 있도록 함\n",
    "\n",
    "p5 :\n",
    "* 이미 확률이론과 정보이론에 익숙하다면 이 장을 넘어가도 됨(3.14를 제외하고)\n",
    "    - 3.14 section : machine learning 위한 structured probabilistic models을 설명하기 위한 그래프(graphs)에 대해 소개함\n",
    "* 확률 및 정보 이론에 대한 추가적인 자료 : Jaynes (2003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Why Probability\n",
    "p1 (**page 54**) :\n",
    "* 컴퓨터공학에서는 대부분 결정론적(deterministic)이고 확실한(certain) 엔터티(entities)를 다룸\n",
    "    * 프로그래머는 보통 CPU가 각각의 머신 명령어(machine instruction)를 완벽하게 실한한다고 가정할 수 있음\n",
    "    * 하드웨어에서의 오류가 발생하지만, 대부분의 소프트웨어 어플리케이션에서 이러한 오류를 다룰 필요가 없을 정도로 잘 발생하지 않음\n",
    "    * 많은 컴퓨터 공학 및 소프트웨어 엔지니어링 분야에서는 상대적으로 clean하고 certain한 환경에서 작업이 이루어지는 것을 감안할 때, machine learning이 probability theory를 heavy하게 사용하는 것은 놀라운 일임\n",
    "\n",
    "p2 :\n",
    "* machine learning은 반드시 불확실한 양(quantities)를 다루고, 때때로 결적정이지 않은(non-deterministic) 확률론적인(stochastic) 양을 다룰 필요가 있음\n",
    "* 1980년대 이후, 확률을 사용하여 불확실성을 정량화하기위한 시도들이 나타남\n",
    "* *참고* : Pearl (1988)\n",
    "\n",
    "p3 : \n",
    "* 불확실성이 존재할 때, 추론할 수 있는 능력이 필요함\n",
    "\n",
    "    불확실성의 원인은 세가지 있음\n",
    "    1. 모델링중인 시스템의 고유 확률: 양자 역학에 대한 대부분의 해석은 아 원자 입자의 역학이 확률적이라고 설명함\n",
    "        - 예를들어, 임의의(random) 역학을 갖는다고 가정하는 이론적인 시나리오를 만들 수 있음\n",
    "            - 가상 카드 게임(hypothetical card game) : 카드가 무작위 순서로 섞여(shuffled) 있다고 가정\n",
    "    2. 불완전한 관측성: 시스템조차도 시스템의 동작을 유발하는 모든 변수를 관찰할 수 없을 때, 확률적으로 보일 수 있음\n",
    "        - 예를들어, 세개의 문이 있고, 두개의 문에는 염소, 하나의 문에는 차를 두고, 해당 문을 열었을 때, 해당하는 경품을 주는 컨테스트가 있다고 생각해보자!\n",
    "            - 참가자의 선택으로 인한 결과는 결정적임\n",
    "            - 반면, 참가자 관점에서는 어떤 문에서 어떤 결과가 나타날지 불확실함\n",
    "    3. 불완전한 모델링: 관측한 정보의 일부를 반드시 버려야 하는 model을 사용할 때, 버려진 정보는 model의 예측에 불확실성을 초래할 수 있음\n",
    "        - 예를들어, 주변의 모든 개체(object)의 위치를 관측하는 로봇을 구현한다고 생각해보자!\n",
    "            - 개체의 미래 위치를 예측할 때, 해당 공간을 이산화(discretize)한다면,\n",
    "            - 이러한 이산화 작업은 모델의 예측에 불확실성을 전가함\n",
    "                - 각 개체들은 이산화된 cell의 어느 위치에도 존재할 수 있음\n",
    "    \n",
    "p4 (**page 55**) :\n",
    "* 많은 상황에서, 실제 룰이 결정론적이고 모델링 시스템이 복잡한 룰을 수용할 수 있다 할지라도, \n",
    "* 불확실하지만 단순한 룰을 사용하는 것이, 확실하지만 복잡한 룰을 사용하는 것보다 더 실용적인 경우가 많음\n",
    "> For example, the simple rule “Most birds fly” is cheap to develop and is broadly useful, while a rule of the form, “Birds fly, except for very young birds that have not yet learned to fly, sick or injured birds that have lost the ability to fly, flightless species of birds including the cassowary, ostrich and kiwi. . . ” is expensive to develop, maintain and communicate, and after all of this effort is still very brittle and prone to failure.\n",
    "\n",
    "p5 :\n",
    "\n",
    "* 확률이론이 인공지능 어플리케이션을 위한 모든 도구(tool)들을 제공할 수 있다고 하는것은 즉시(immediately) 명백하지(obvious) 않음\n",
    "* 확률이론은 원래 사건이 일어나는 빈도를 분석하기 위해 개발되었음\n",
    "    * 포커게임해서 특정 카드를 뽑는 것과 같은 사건을 연구하기 위해 확률 이론이 어떻게 사용되었는지 알 수 있음\n",
    "    * 이러한 사건은 종종 반복적으로 발생함\n",
    "    * 결과가 확률 $ p $로 발생함\n",
    "        * experiments (e.g., 카드를 뽑는 행위)를 무한히 반복한다면, 해당 사건이 반복되어 나타난 비율(proportion) $ p $는 확률 $ p $와 같다고 할 수 있음\n",
    "    * 반면, 이러한 추리 방법은 반복적으로 발생하지 않는 상황에서는 직접적으로 적용이 불가능함\n",
    "    * 예를 들면, 환자가 독감에 걸린 확률이 40%라고 한다면??\n",
    "        * 환자마다의 조건(특성)이 모두 다르기 때문에, 환자 각각에게 이 이론을 적용하기에는 힘듦\n",
    "        * 이 경우, 신뢰도(**degree of belief**)를 나타내는 확률을 사용할 수 있음 \n",
    "            * 1인 경우 : 환자가 절대적으로 확실하게 독감에 걸렸다는 것을 가리킴\n",
    "            * 0인 경우 : 환자가 절대적으로 확실하게 독감에 걸리지 않았다는 것을 가리킴\n",
    "\n",
    "* **frequentiest probability** : 사건이 발생할 비율과 직접적인 연관이 있는 확률\n",
    "* **Bayesian probability** : 불확실성의 질적 수준(qualitative levels)과 연관이 있는 확률\n",
    "\n",
    "p6 :\n",
    "* Bayesian probabilities가 frequentiest probabilities와 정확히 동일하게 취급함으로써, 불확실성에 대한 common sense reasoning을 기대할 수 있음\n",
    "    * certain set of cards가 있을 때, 플레이어가 포커 게임에 이길 확률\n",
    "    * certain symtoms가 있을 때, 환자가 병을 가지고 있을 확률\n",
    "    * 위 두 확률을 하나의 같은 formulas를 이용해서 구할 수 있음\n",
    "* *참고* : Ramsey(1926)\n",
    "\n",
    "\n",
    "p7 (**page 56**) :\n",
    "* 확률은 불확실성을 다루기위한 논리의 확장으로 볼 수 있음\n",
    "* 이런 논리는 명제가 참이거나 거짓이라는 가정하에 어떤 명제가 참인지 거짓인지를 결정하기 위한 일련의 공식을 제공함 --> 베이지안 확률\n",
    "* 확률 이론은 다른 명체의 가능성(likelihood)을 고려하여 명제의 가능성을 결정하기 위한 일련의 공식을 제공함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Random Variables\n",
    "\n",
    "p1 :\n",
    "* random variable은 다른 값을 무작위로 취할 수 있는 값을 의미함\n",
    "* random variable은 가능한 상태(states)에 대한 description 임\n",
    "    * random variable은 반드시 각 상태들이 어떻게 나타나는지를 표현하는 probability distribution과 연결되어야 함\n",
    "\n",
    "p2 :\n",
    "* random variable은 이산(discrete) 혹인 연속(continous)일 수 있음\n",
    "* discrete random variable : 유한하거나, 셀 수 있는 무한한 수의 상태(states)를 갖는 variable\n",
    "    * states는 반드시 정수(integers)가 될 필요는 없음\n",
    "* continous random variable : real value와 연관된 variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Probability Distributions\n",
    "\n",
    "p1 :\n",
    "* probability distribution : 확률 변수이나 확률 변수의 집합이 취할 수 있는 가능한 각 상태들에 대한 설명(description)\n",
    "* variable이 이산인지, 연속인지에 따라 probability distribution을 설명하는(describe) 방법이 달라짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Discrete Variable and Probabiltiy Mass Functions\n",
    "\n",
    "p1 :\n",
    "* discrete variable에서의 확률 분포는 Probability mass function(PMF, 확률질량함수)를 사용하셔 설명할 수 있음\n",
    "* random variable을 서로 다른 probability mass function과 연관지을 수 있음\n",
    "> Often we associate each random variable with a different probability mass function and the reader must infer which probability mass function to use based on the identity of the random variable, rather than the name of the function; $ P(x) $ is usually not the same as $ P(y) $.\n",
    "\n",
    "p2(**page 57**) :\n",
    "* probability mass function은 random variable의 state를 해당 state를 갖을 random variable의 확률로 매핑함\n",
    "* $ \\text{x} = x $ 의 확률 : $ P(x) $\n",
    "    + $ P(x) = 1 $ : $ \\text{x} = x $ 가 명백한(certain) 경우\n",
    "    + $ P(x) = 0 $ : $ \\text{x} = x $ 가 불가능할 경우\n",
    "* 사용하고자 하는 PMF를 명확하게 하기 위해 random variable을 $ P(\\text{x} = x) $ 와 같이 명시적으로 표기할 수 있음\n",
    "* $ \\sim $ notation을 활용해서, random variable이 어떤 distribution을 따르는지 명시할 수 있음 : $ \\text{x} \\sim P(x) $\n",
    "\n",
    "p3 :\n",
    "* **joint probability distribution** ($ P(\\text{x}=x, \\text{y}=y) $) : \n",
    "    - 동시에 여러 variable들에 Probability mass function들이 적용될 수 있음\n",
    "\n",
    "![pic01](https://user-images.githubusercontent.com/19326012/75846618-3b97f400-5e20-11ea-88a6-db082eeef5e3.PNG)\n",
    "\n",
    "\n",
    "p4 :\n",
    "* 확률 변수 x에 대한 확률질량함수가 되기 위해서는 함수 P가 다음과 같은 조건을 만족해야함\n",
    "    1. $ P $ 는 x의 가능한 모든상태의 집합이여야 함\n",
    "    2. 모든 확률변수 \\\\(x \\\\)는 집합 x에 속하며 확률 밀도함수 P(x)는 0과 1사이의 수이며 불가능한 사건의 확률은 0이고 사건이 반드시 일어날 확률은 1임\n",
    "        - $ \\forall x \\in \\text{x}, 0 \\leq P(x) \\leq 1 $\n",
    "    3. 모든 확률변수의 합은 1이며 이는 정규화되는 것을 의미하기도 함, 이를 이용해서 많은 사건 중 하나의 사건이 발생할 확률을 구하거나 하나의 발생할 사건을 계산하여 하나보다 큰 확률을 얻을 수 있음\n",
    "        - $ \\sum_{x \\in \\text{x}} P(x) = 1 $\n",
    "    \n",
    "p5 :\n",
    "* 예를들어, 단일 이산 확률 변수 x가 k개의 다른 상태를 가지고 있다고 생각해보자!\n",
    "    - x에 대해 균등분포(**uniform distribution**)를 적용할 수 있음\n",
    "    - 이는 각각의 상태를 모두 같은 확률로 나타나도록 만드는 것을 의미함\n",
    "    - $ P(\\text{x} = x_i) = \\frac{1}{k} \\text{ for all } i $\n",
    "    \n",
    "* 또한 이 표현은 확률 질량 함수의 조건에 충족하는 것을 볼 수 있음, 즉, \n",
    "\n",
    "![pic02](https://user-images.githubusercontent.com/19326012/75846517-f1af0e00-5e1f-11ea-9f7e-56b45d280314.PNG)\n",
    "\n",
    "![pic03](https://user-images.githubusercontent.com/19326012/75846522-f5db2b80-5e1f-11ea-8550-b0678d718fb9.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Continuous Variables and Probability Denstiy Functions\n",
    "\n",
    "p1(**page 58**) : \n",
    "\n",
    "* 연속확률변수가 있을 때, 확률 분포를 설명하고자 할 경우, 확률 질량 함수가 아닌 확률 밀도 함수(**probability density function, PDF**)를 사용함\n",
    "* 확률 밀도 함수는 다음과 같은 조건을 만족해야 함\n",
    "    1. p는 x의 가능한 모든상태의 집합이여야 함\n",
    "    2. $ p(x) \\leq 1 $ 을 만족할 필요는 없으나, 다음을 만족해야 함\n",
    "        - $ \\forall x \\in \\text{x}, p(x) \\geq 0 $\n",
    "    3. 모든 확률 변수의 합은 1임\n",
    "        - $ \\int p(x) dx = 1 $\n",
    "    \n",
    "p2 :\n",
    "* 확률 밀도 함수는 특정 상태의 확률을 나타내주진 않지만, \n",
    "* 대신 $ p(x) \\delta x $ 로 주어지는 부피 $ \\delta x $ 를 갖는 무한 영역 내에서의 확률을 나타낼 수 있음\n",
    "    \n",
    "p3 :\n",
    "* 밀도 함수를 적분해서 실제 확률 질량을 찾을 수 있음\n",
    "* 특히, x가 일부 집합 S에 있는 확률은 해당 집합에 대한 P(x)의 적분에 의해 주어짐\n",
    "* univariate example : \n",
    "    - $ \\int _{[a, b]}p(x)dx $\n",
    "    \n",
    "p4 :\n",
    "* 실수 구간에 대한 균일 분포를 고려하면 특정 확률 밀도에 해당하는 확률 밀도함수의 예를 알아낼 수 있음\n",
    "* 함수 $ u(x;a,b) $를 사용하여 이를 나타낼 수 있는데, 이 때, a와 b를 구간의 끝점이고 x는 함수의 인수임\n",
    "* 구간 밖의 확률 질량이 없다고 보장하기 위해,\n",
    "    - $ u(x;a,b) = 0 \\text{ for all } x \\notin [a, b] $\n",
    "    - $ u(x;a,b) = \\frac {1} {b-a} \\text{ for all } x \\in [a, b] $\n",
    "\n",
    "![pic05](https://user-images.githubusercontent.com/19326012/75846530-fbd10c80-5e1f-11ea-8f9d-150a8852bf49.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Marginal Probability\n",
    "p1 :\n",
    "* 모든 variable들의 집합 대한 probability distribution을 알고 있고, 그 중 일부 집합(subset)에 대한 probability distribution을 알고자 할 때 사용함\n",
    "* **marginal probability**:일부 집합에 대한 probability distribution\n",
    "\n",
    "p2 :\n",
    "* 만약 이산 확률 변수 x,y가 있다면, 그리고 그 확률 분포 P(x,y)를 알고 있다면,\n",
    "* $ P(x) $를 다음의 **sum rule**을 이용해서 구할 수 있음\n",
    "\n",
    "![pic06](https://user-images.githubusercontent.com/19326012/75846536-01c6ed80-5e20-11ea-8d72-1477911d1ac6.PNG)\n",
    "\n",
    "p3(**page 59**) : \n",
    "\n",
    "![pic06_1](https://i0.wp.com/www.statistics-made-easy.com/wp-content/uploads/2016/08/marginal-probability.png?resize=467%2C242)\n",
    "\n",
    "p4 :\n",
    "* 연속 확률 변수에서는, summation 대신 integration을 사용함\n",
    "\n",
    "$$ \n",
    "    p(x) = \\int p(x, y)dy\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Conditional Probability\n",
    "\n",
    "p1 :\n",
    "* **conditional probability** : 다른 사건이 발생했을 때, 특정 사건이 발생할 확률\n",
    "* $ P(\\text{y}=y | \\text{x}=x) $ : $ \\text{x} = x $ 일 때, $ \\text{y} = y $일 확률\n",
    "\n",
    "![pic07](https://user-images.githubusercontent.com/19326012/75846546-07243800-5e20-11ea-8e31-2afcafc3e656.PNG)\n",
    "\n",
    "* 조건부 확률은 $ P(\\text{x} = x) > 0 $ 인 경우에만 정의됨\n",
    "* 사건이 일어나지 않은 상태에서의 조건부확률은 계산 불가능\n",
    "\n",
    "p2 :\n",
    "* 어떤 행위를 취했을 때 발생하는 것을 계산하는 것과, 조건부 확률을 혼동하지 않는 것이 중요함\n",
    "    * 예를 들어, 독일어를 할 줄 아는 사람이 독일에서 온 확률은 높지만\n",
    "    * 무작위로 선택된 사람이 독일어를 말하도록 가르쳐도 그들이 독일인이 되지는 않음\n",
    "* 행위의 결과를 계산하는 것 : **intervention query**를 만드는 것 - **causal modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 The Chain Rule of Conditional Probabilities\n",
    "\n",
    "p1 : \n",
    "* 많은 확률변수에 대한 결합확률분포는 conditional distribution으로 나누어질 수 있음\n",
    "\n",
    "![pic08](https://user-images.githubusercontent.com/19326012/75846556-0c818280-5e20-11ea-86dc-4460050786e1.PNG)\n",
    "\n",
    "\n",
    "* 이를 **chain rule** 또는 확률의 **product rule** 이라고 함\n",
    "* 이러한 chain rule은 조건부 확률 정의 식(3.5) 로부터 직접적으로 유도할 수 있음\n",
    "\n",
    "$$\n",
    "    P(a, b, c) = P(a | b, c) P(b, c)\n",
    "$$\n",
    "$$\n",
    "    P(b, c) = P(b | c) P(c)\n",
    "$$\n",
    "$$\n",
    "    P(a, b, c) = P(a | b, c) P(b | c) P(c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Independence and Conditional Independence(조건부 독립성)\n",
    "\n",
    "p1 :\n",
    "* 두 확률 분포가 서로 곱으로 표현 될 수 있는 경우, 두 random variable은 독립(**independent**)임\n",
    "\n",
    "$$\n",
    "    \\forall x \\in \\text{x}, \\forall y \\in \\text{y}, p(\\text{x} = x, \\text{y} = y) = p(\\text{x} = x) p(\\text{y} = y)\n",
    "$$\n",
    "\n",
    "p2 :\n",
    "* 만약 모든 random variable $ z $에 대해, 조건부 확률 분포가 random variable x, y로 인수분해(factorize) 되면, \n",
    "* 두 random variable x, y는 조건부 독립(**conditionally independent**)임\n",
    "\n",
    "![pic09](https://user-images.githubusercontent.com/19326012/75846562-12776380-5e20-11ea-9c0f-b831d7ac23d8.PNG)\n",
    "\n",
    "\n",
    "p3 :\n",
    "* x⊥y : x와 y가 독립\n",
    "* x⊥y|z : x와 y가 z에 대해 조건부 독립"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Expectation, Variance and Covariance\n",
    "\n",
    "p1 :\n",
    "* 확률 분포 p(x)와 관련하여 함수 f(x)의 기댓값(**expectation**, **expected value**) :\n",
    "    - $ x $가 $ P $에서 추출될 때, $ f $가 취하는 평균 또는 평균값임\n",
    "* discrete variable case :\n",
    "$$\n",
    "    \\mathbb{E}_{\\text{x} \\sim P}[f(X)] = \\sum_x P(x)f(x)\n",
    "$$\n",
    "* continuous variable case:\n",
    "$$\n",
    "    \\mathbb{E}_{\\text{x} \\sim p}[f(X)] = \\int_x p(x)f(x)dx\n",
    "$$\n",
    "\n",
    "p2(**page 61**) :\n",
    "\n",
    "* 기대값은 선형(linear)성을 갖음\n",
    "    * $ \\alpha $와 $ \\beta $ 가 $ x $에 의존하지 않을 때,\n",
    "    \n",
    "![pic12](https://user-images.githubusercontent.com/19326012/75846568-17d4ae00-5e20-11ea-9727-fedfa7dedbb5.PNG)\n",
    "\n",
    "\n",
    "p3 :\n",
    "\n",
    "* 분산(**variance**) : 확률 분포에서 샘플링 된 x와 랜덤 변수 x의 함수 값이 얼마나 다른지 측정함\n",
    "\n",
    "![pic11](https://user-images.githubusercontent.com/19326012/75846574-1c996200-5e20-11ea-95a7-0f3dc9ac24a8.PNG)\n",
    "\n",
    "* 분산의 값이 낮으면, $ f(x) $의 값이 기댓값에 가까운 것을 의미함\n",
    "* 표준편차(**standard deviation**) : 분산의 제곱근\n",
    "\n",
    "p4 :\n",
    "* **covariance** : 두 변수가 서로 얼마나 선형적 관계를 갖는지에 대한 지표로 해석할 수 있음\n",
    "    * 또한 이 두 변수의 scale에 대해서도 나타낼 수 있음\n",
    "\n",
    "![pic13](https://user-images.githubusercontent.com/19326012/75846591-21f6ac80-5e20-11ea-84fe-8c1cbb503327.PNG)\n",
    "\n",
    "* covariance이 절대값이 높으면\n",
    "    - 두 값들의 변화가 매우 많은 것을 의미하고, 두 값이 각각의 평균으로부터 멀다는 것을 의미함\n",
    "    \n",
    "* covariance의 부호가 양수라면\n",
    "    - 두 변수는 동시에 비교적 높은 값을 가지는 경향이 있음\n",
    "* covariance의 부호가 음수라면\n",
    "    - 하나의 변수는 높은 값을 가지지만 동시에 다른 값은 상대적으로 낮은 값을 가지는 경향이 있음\n",
    "* **correlation**과 같은 measures는 개별 변수의 scale에 따라 영향을 받지 않고, 변수들이 얼마나 연관되어 있는지 측정하기 위해 각 변수의 기여도를 정규화(normalize)함\n",
    "\n",
    "p5 :\n",
    "* 공분산(corvariance)의 개념과 종속(dependence)은 서로 연관성을 가지지만 서로 다른 특징을 가짐\n",
    "    * 독립적인 두 변수 사이의 공분산은 0을 나타냄\n",
    "    * 종속적인 두 변수 사이의 공분산은 0이 아닌 값을 나타냄\n",
    "    \n",
    "* 반면. 독립(independence)은 공분산의 개념과 구별됨\n",
    "    * 독립적인 관계의 두 변수의 공분산은 0이지만, **공분산이 0인 두변수는 독립적일 수도 있고 아닐 수도 있음**\n",
    "        - 즉, 공분산이 0이라고 해서 항상 독립은 아님\n",
    "        - 두 변수가 종속관계일지라도 공분산 0을 갖을 수 있음\n",
    "        - 예시)\n",
    "            - 실수(real number) $ x $ : $ [-1, 1] $의 uniform distribution에서 샘플링된 변수\n",
    "            - random variable $ s $ : $ \\frac {1}{2} $의 확률로 1 혹은 -1로 선택되는 변수\n",
    "            - $ y = sx $\n",
    "            - $ x $가 $ y $의 크기(magnitude)를 결정하므로, 두 변수는 독립이 아님\n",
    "            - 그러나, $\\text{Cov}(x,y) = 0 $\n",
    "            \n",
    "![pic14](https://t1.daumcdn.net/cfile/tistory/2533B54B58BD19341C)\n",
    "\n",
    "※ https://destrudo.tistory.com/15\n",
    "\n",
    "p6(**page 62**) :\n",
    "* random vector $ x \\in \\mathbb{R}^n $의 **cpovariance matrix**는 $ n \\times n $ 의 배열이며 다음과 같음\n",
    "\n",
    "$$\n",
    "    \\text{Cov}(\\mathbf{x})_{i, j} = \\text{Cov}(\\text{x}_i, \\text{x}_j)\n",
    "$$\n",
    "\n",
    "* 공분산 행렬의 대각 요소 : 분산\n",
    "\n",
    "$$\n",
    "    \\text{Cov}(\\text{x}_i, \\text{x}_i) = \\text{Var}(\\text{x}_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.9 Common Probability Distributions\n",
    "\n",
    "p1 :\n",
    "- 머신 런닝에서 여러 간단한 확률 분포가 유용하게 쓰임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.1 Bernoulli Distribution\n",
    "p1.\n",
    "- 베르누이 분포는 **binary random variable**에 대한 분포\n",
    "- 이 분포는 단일 파라미터 ${\\phi \\in[0, 1]}$ 에 의해 결정되고, ${\\phi}$는 random variable이 1이 될 때의 확률을 나타냄\n",
    "- ${\\phi}$는 다음과 같은 특성을 가심\n",
    "\n",
    "$${P(x=1)=\\phi}$$\n",
    "$${P(x=0)=1-\\phi}$$\n",
    "$${P(x=X)=\\phi ^x (1-\\phi)^{1-x}}$$\n",
    "$${\\mathbb{E}_x[x]=\\phi}$$\n",
    "$${\\text{Var}_x(x)=\\phi (1-\\phi)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.2 Multinoulli DIstribution\n",
    "p1 : \n",
    "- **multinoulli** 또는 **categorical** distribution : 유한한 서로 다른 k개의 상태를 갖는 단일 discrete variable 의 분포\n",
    "    - 벡터 ${p \\in [0,1]^{k-1}}$에 의해 파라미터화 됨\n",
    "        - ${p_i}$는 i 번째 상태의 확률을 의미\n",
    "        - 마지막 k 번째 상태의 확률은 ${1-1^{\\top}p}$로 주어짐 (이 때의 제약사항: ${1^{\\top}p \\leq 1}$)\n",
    "    - 대상(objects)의 여러 'categories'에 대한 분포를 언급할 때 사용됨\n",
    "        - 주로 상태 1이 수치 1을 가진다고 가정하지 않음\n",
    "        - 따라서, multinoulli하게 분포하는 random variable들의 기대값(expectation)이나 분산(variance)을 계산할 필요 없음\n",
    "\n",
    "p2(**page 63**) : \n",
    "- Bernoulli, multinoulli 분포는 이 도메인에서의 어떠한 분포라도 표현하기 적절\n",
    "    - 모든 변수를 열거하기 위해 이산적 변수를 모델링하여 강력하지만 오히려 도메인이 단순하기 때문에 도메인의 어떠한 분포라도 충분히 설명할 수 없음\n",
    "    - continuous variable들을 다룰 때 셀 수 없이 많은 상태가 도출되고 작은 수의 파라미터로 표현되는 분포는 정밀한 제약을 두어야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.3 Gaussian Distribution\n",
    "p1 :\n",
    "- 실수 체계에서 가장 널리 쓰이는 분포는 정규 분포(**normal distribution**)으로 가우시안 분포(**Gaussian distribution**)로도 알려짐\n",
    "\n",
    "$${\\begin{equation*}N(x:\\mu,\\sigma^2)=\\sqrt{\\frac{1}{2 \\pi \\sigma^2}}\\text{exp}(\\frac{-1}{2 \\sigma ^2}(x- \\mu)^2)\\end{equation*}}$$\n",
    "\n",
    "- 밀도 함수를 나타내는 Figure 3.1\n",
    "\n",
    "![image1](https://user-images.githubusercontent.com/19326012/75846659-59655900-5e20-11ea-9d82-9ae92e90d7f5.PNG)\n",
    "\n",
    "\n",
    "\n",
    "p2 :\n",
    "- ${\\mu \\in \\mathbb{R}}$, ${\\sigma \\in (0, \\infty)}$ : normal distribution의 control parameter\n",
    "    - ${\\mu}$ : 곡선의 최고점이자 평균을 의미 ${E[x]=\\mu}$\n",
    "    - ${\\sigma}$ : 분포의 표준편차로 분산은 ${\\sigma^2}$으로 표현\n",
    "\n",
    "p3 :\n",
    "- PDF를 평가할 때 ${\\sigma}$를 제곱하고 역수를 취함\n",
    "- 다른 파라미터 값들로 자주 PDF를 평가하고자 할 때, 분포를 파라미터(모형)화하는 더 효율적인 방법은 파라미터 ${\\beta \\in (o, \\infty)}$를 이용하여 분포의 '정확도(precision)' 또는 역분산(inverse variance)를 제어하는 것임\n",
    "\n",
    "$${N(x:\\mu,\\beta^{-1})=\\sqrt{\\frac{\\beta}{2 \\pi}}\\text{exp}(-\\frac{1}{2}\\beta(x- \\mu)^2)}$$\n",
    "\n",
    "p4(**page 64**) :\n",
    "- 정규 분포는 많은 응용에 실용적\n",
    "- 실수가 취해야하는 분포의 형태(form)에 대한 사전 지식(prior knowledge)이 없을 경우, 정규 분포는 다음의 두 가지 이유로 default choice로 사용하기 좋음\n",
    "\n",
    "    1. 모델링하고자 하는 대부분의 분포들은 정규분포에 엄밀히 가까움\n",
    "        - 중심극한정리(**central limit theorem**)는 많은 독립적 랜덤 변수들의 합이 정규 분포에 근사되는 것을 보여줌\n",
    "        - 즉, 실제로 사용할 때 많은 복잡한 시스템들이 더 구조화된 동작을 갖는 여러 부분으로 분해되더라도, 성공적으로 정규 분포화된 노이즈로 모델링될 수 있음\n",
    "    2. 같은 분산을 갖는 모든 가능한 확률 분포들에서, 정규 분포는 real number 전반에 걸친 maximum amount of uncertainty를 encode함\n",
    "        - 즉, 정규 분포는 모델에 사전 지식을 **최소한**으로 삽입한다고 생각할 수 있음\n",
    "        - 이 기법을 완전히 개발하고 정당화하기 위해선 많은 수학적 기법이 요구되고 19.4.2장 까지 미룸\n",
    "\n",
    "p5 : \n",
    "- 정규 분포는 ${R^n}$로 일반화될 수 있으며, '다변수 정규 분포(**multivariate normal distribution**)'라 함\n",
    "    - 이 분포는 positive definite symmetric matrix인 ${\\Sigma}$로 파라미터화될 수 있음\n",
    "\n",
    "$${N(x;\\mu,\\Sigma)=\\sqrt{\\frac{1}{(2\\pi)^n det(\\Sigma)}}\\text{exp}(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu))}$$\n",
    "\n",
    "\n",
    "p6(**page 65p**) :\n",
    "- ${\\mu}$ : 분포의 평균, 벡터 값\n",
    "- ${\\Sigma}$ : 공분산 행렬\n",
    "- 다변수의 경우이므로 PDF를 다른 값들의 파라미터에 대해 평가할 때, 공분산 행렬 ${\\Sigma}$를 역수 취해야하기 때문에 계산적으로 분포를 파라미터화 하는데 효율적이지 못함\n",
    "- 대신 '정확도 행렬 (**precision matrix**)' ${\\beta}$를 사용\n",
    "\n",
    "$${N(x;\\mu,\\beta^{-1})=\\sqrt{\\frac{det(\\beta)}{(2\\pi)^n}}\\text{exp}(-\\frac{1}{2}(x-\\mu)^T\\beta(x-\\mu))}$$\n",
    "\n",
    "p7 :\n",
    "- 종종 공분산 행렬을 대각 행렬(diagonal matrix)로 바꾸기도 함\n",
    "- 더 간단한 방법으로는 방향에 상관없는 성질의 등방성(**isotropic**) 가우시안 분포로 분산 행렬은 identity 행렬에 스칼라 곱임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.4 Exponential and Laplace Distributions\n",
    "p1 :\n",
    "- 딥 러닝의 맥락에서, 종종 ${x=0}$에서 sharp point를 갖는 확률 분포가 필요함\n",
    "    - 이 경우, 지수 분포(**exponential distribution**)를 사용\n",
    "\n",
    "$${p(x;\\lambda)=\\lambda1_{x \\geq 0}\\text{exp}(-\\lambda x)}$$\n",
    "\n",
    "- 지수 분포는 지시 함수 (indicator function) ${1_{x \\geq 0}}$을 사용하여, 모든 음의 값 ${x}$에 확률 0을 부여\n",
    "\n",
    "![img1](https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Exponential_probability_density.svg/650px-Exponential_probability_density.svg.png)\n",
    "\n",
    "p2 :\n",
    "- 확률 질량의 sharp peak를 무작위 점 ${\\mu}$에 지정할 수 있게 하는 확률 분포를 '라플라스 분포(**Laplace  distribution**)'라 함\n",
    "\n",
    "$${Laplace(x;\\mu,\\gamma)=\\frac{1}{2\\gamma}\\text{exp}(-\\frac{|x-\\mu|}{\\gamma})}$$\n",
    "\n",
    "![img2](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Laplace_pdf_mod.svg/650px-Laplace_pdf_mod.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.5 The Dirac Distribution and Empirical DIstribution\n",
    "p1 :\n",
    "- 어떤 경우엔 확률 분포의 질량이 한 점 주위로 클러스터하는 것을 구체적으로 명시해야할 필요가 있음\n",
    "    - 이 경우, PDF를 **Dirac delta 함수** ${\\delta(x)}$로 정의\n",
    "\n",
    "$${p(x)=\\delta(x-\\mu)}$$\n",
    "\n",
    "- Dirac delta 함수는 0을 제외한모든 부분에서 0의 값을 갖지만, 적분 결과는 1임\n",
    "\n",
    "- Dirac delta 함수는 각 ${x}$값을 실수화된 결과와 연관시키는 일반 함수가 아님\n",
    "    - '일반화된 함수(**generalized function**)'\n",
    "\n",
    "- Dirac delta 함수는 0이 아닌 모든 점에 매우 작은 수 대입하는 일련의 함수의 limit point라 할 수 있음\n",
    "\n",
    "p2(**66 page**) :\n",
    "- ${p(x)}$를 ${-\\mu}$만큼 이동한(shifted) ${\\delta}$로 정의함으로써, ${x=\\mu}$에서 무한히 좁고 무한히 높은 확률 질량을 얻을 수 있음\n",
    "\n",
    "![img3](https://upload.wikimedia.org/wikipedia/commons/b/b4/Dirac_function_approximation.gif)\n",
    "\n",
    "p3 :\n",
    "- 일반적으로 Dirac delta 분포는 '**empirical distribution**'의 구성요소로 간주할 수 있음\n",
    "\n",
    "$${\\hat{p}(x)=\\frac{1}{m}\\left(\\sum_{i=1}^m \\delta(x-x^{(i)}) \\right)^2}$$\n",
    "\n",
    "- 주어진 데이터 셋 혹은 샘플들의 집합을 형성하는 각 ${m}$ 포인트 ${x^{(1)},...,x^{(m)}}$에 확률 질량 ${\\frac{1}{m}}$을 대입\n",
    "\n",
    "- Dirac delta 함수는 연속적인 변수들에 대한 경험적 분포를 정의하기 위해서만 필요\n",
    "- 이산 변수에 대해선 문제가 더 간단\n",
    "    - 경험적 분포는 training set내 값의 '경험적 빈도(**empirical frequency**)'와 동일한, 각 각능한 입력 값 과 연관된 확률을 통해 multinoulli 분포로 개념화될 수 있음\n",
    "\n",
    "p4.\n",
    "- training examples의 데이터셋으로부터 형성된 경험적 분포를, 모델을 학습시킬 때 얻을 수 있는 sample 분포로 명시한 것이라 할 수 있음(section 5.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.6 Mixtures of Distributions\n",
    "p1 :\n",
    "- 단순한 확률 분포들을 결합하여 확률 분포를 정의하는 것은 매우 일반적\n",
    "    - '**mixture distribution**'을 만드는 것\n",
    "    - multinoulli 분포로부터 component identity를 sampling 함으로써, 어떤 component distribution이 sample을 생성할 것인지를 결정함\n",
    "\n",
    "$${P(x)= \\sum_{i}P(c=i)P(x|c=i)}$$\n",
    "\n",
    "- ${P(c)}$는 multinoulli 분포로 구성 요소 identities에 대한 분포\n",
    "\n",
    "p2 : \n",
    "- 3.9.5 내용은 mixture distribution의 예시: real-valued 변수들에 대한 empirical distribution은 각각의 traning example들에 대해 각각의 Dirac component를 갖는 mixture distribution으로 간주할 수 있음\n",
    "\n",
    "p3(**page 67**) :\n",
    "- 혼합 모델은 **richer** 분포를 생성하기 위한 확률 분포들을 결합하는 간단한 기법\n",
    "- 16장에서 더 자세하게 간단한 분포들로부터 복잡한 확률 분포들을 생성하는 기법을 살펴볼 것\n",
    "\n",
    "p4 :\n",
    "- 혼합 모델은 후에 나올 가장 중요한 개념인 '잠재 변수(**latent variable**)'에 대해 짧게 소개\n",
    "- latent variable : 직접적으로 관찰할 수 없는 random variable\n",
    "    - latent variable 예시 : mixture model의 component identity variable $ c $\n",
    "    - latent variable은 결합 분포를 통해 x와 연관될 수 있음 : (${P(x,c)=P(x|c)P(c)}$)\n",
    "    - latent variable에 대한 분포 $ P(c) $와, latent variable를 visible variable과 연관시키는 분포 $ P(x | c) $는 $ P(x) $ 분포의 형태를 결정할 수 있음\n",
    "    - latent variable은 16.5장에서 다뤄짐\n",
    "\n",
    "p5 :\n",
    "- 매우 강력하고 흔히 쓰이는 혼합 모델은 '가우시안 혼합(**Gaussian mixture**)'모델임\n",
    "    - components ${p(x|c = i)}$가 Gaussian인 모델\n",
    "    - 각 component는 구분되어 파라미터화된 평균 ${\\mu^{(i)}}$, 공분산 ${\\Sigma^{(i)}}$를 가짐\n",
    "- 몇몇 mixture은 더 많은 제약 사항이 있을 수 있음\n",
    "    - 각 공분산은 제약 사항 ${\\Sigma^{(i)}=\\Sigma,\\forall{i}}$을 통해 공유될 수 있음\n",
    "    - 하나의 가우시안 분포로 가우시안의 혼합은 각 component의 공분산 행렬이 대각(diagonal)이나 등방성(isotropic)이 되게 제약할 수 있음\n",
    "\n",
    "p6 : \n",
    "- 평균과 분산에 더해서, 가우시안 혼합의 파라미터들은 각 구성 요소 i에 대한 '사전 확률' ${\\alpha_i=P(c=i)}$를 명시함\n",
    "- \"사전\"라는 용어는 c에 대해 x를 측정하기 '전' 모델의 신뢰(belief)을 나타냄\n",
    "- 이와 비교하여 '사후 확률' ${P(c|x)}$는 x 측정 '후'에 계산됨\n",
    "- 가우스 혼합 모델은 충분한 성분을 가진 가우스 혼합 모델에 의해 임의의 0이 아닌 특정 오차로 smooth 밀도를 근사화 할 수 있다는 점에서 밀도의 '**universal approximator**'임\n",
    "\n",
    "\n",
    "p7 : figure 3.2 (68p)은 가우시안 혼합 모델로부터의 samples을 보여줌\n",
    "\n",
    "\n",
    "![image2](https://user-images.githubusercontent.com/19326012/75846673-62eec100-5e20-11ea-96c9-a22d8ec97679.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 Useful Properties of Common FUnctions\n",
    "p1 :\n",
    "- 특정 함수들은 확률 분포를 다룰 때 자주 등장함\n",
    "- 특히 딥러닝에서 주로 사용되는 확률 분포 함수 중 하나 : '**logistic sigmoid**':\n",
    "\n",
    "$${\\sigma(x)=\\frac{1}{1=exp(-x)}}$$\n",
    "\n",
    "- logistic sigmoid는 베르누이 분포의 ${\\phi}$ 파라미터를 생성하기 위해 주로 사용됨\n",
    "- 파라미터 ${\\phi}$ 값의 유효한 범위안에 있는 (0,1) 사이의 값을 가지기 때문\n",
    "- figure 3.3 (69p) sigmoid function 그래프\n",
    "\n",
    "![image3](https://user-images.githubusercontent.com/19326012/75846683-6aae6580-5e20-11ea-9837-d3c9cf0e8c03.PNG)\n",
    "\n",
    "- sigmoid function은 함수의 전달인자가 매우 양수에 가깝거나 음수에 가까울 때 포화(**saturates**)됨\n",
    "    - 이는 해당 구간에서 함수가 매우 flat 해지고 입력의 작은 변화들에 insensitive 해지는 것을 의미\n",
    "\n",
    "p2 : \n",
    "- 또다른 자주 쓰이는 함수 : '**softplus**' :\n",
    "\n",
    "$${\\zeta(x)=log(1+exp(x))}$$\n",
    "\n",
    "- softplus 함수는 범위가 ${(0,\\infty)}$이기 때문에 정규분포의 파라미터 ${\\beta}$나 ${\\sigma}$를 생성시키는데 유용함\n",
    "- 이 함수는 sigmoids를 포함하는 식을 잘 처리해야 할 때도 자주 쓰임\n",
    "- softplus 함수의 이름은 다음 식의 smoothed 또는 'softed' 버전에서 유래\n",
    "\n",
    "$${x^+=max(0,x)}$$\n",
    "\n",
    "- figure 3.4 (69p) softplus 함수 그래프\n",
    "\n",
    "![image4](https://user-images.githubusercontent.com/19326012/75846694-700bb000-5e20-11ea-873b-66bcd7b612c5.PNG)\n",
    "\n",
    "\n",
    "p3(**page 70**) : \n",
    "- 다음의 특성들은 충분히 기억할 만할 것\n",
    "\n",
    "$${\\sigma(x)=\\frac{exp(x)}{exp(x)+exp(0)}}$$\n",
    "$${\\frac{d}{dx}\\sigma(x)=\\sigma(x)(1-\\sigma(x))}$$\n",
    "$${1-\\sigma(x)=\\sigma(-x)}$$\n",
    "$${log\\sigma(x)=-\\zeta(-x)}$$\n",
    "$${\\frac{d}{dx}\\zeta(x)=\\sigma(x)}$$\n",
    "$${\\forall{x}\\in(0,1), \\sigma^{-1}(x)=log(\\frac{x}{1-x})}$$\n",
    "$${\\forall{x}>0, \\zeta^{-1}(x)=log(exp(x)-1)}$$\n",
    "$${\\zeta(x)=\\int_{-\\infty}^x\\sigma(y)dy}$$\n",
    "$${\\zeta(x)-\\zeta(-x)=x}$$\n",
    "\n",
    "- 함수 ${\\sigma^{-1}|$는 통계학에서 'logit'이라 불리는데 머신 러닝에서 이 용어는 잘 쓰이지 않음\n",
    "\n",
    "p4 : \n",
    "- 식 ${\\zeta(x)-\\zeta(-x)=x}$은 이름 \"softplus\"에 대한 추가적 타당성을 제시\n",
    "- softplus 함수는 수식 ${x^+=\\max(0,x)}$, '양수 부분'의 smoothed 버전\n",
    "- 양의 부분 함수는 '음의 부분' 함수, ${x^-=\\max(0,-x)}$와 반대됨\n",
    "- 음의 부분과 동일한 smooth 함수를 얻기 위해서 ${\\zeta(-x)}$를 사용\n",
    "    - x는 양과 음의 부분에서부터 identity ${x^+-x^-=x}$를 통해 복구될 수 있기 때문에 같은 관계인 $ {\\zeta(x)| }$와 ${\\zeta(-x)}$를 이용하여 x 복구 가능, figure 3.4 (69p)\n",
    "\n",
    "![image4](https://user-images.githubusercontent.com/19326012/75846694-700bb000-5e20-11ea-873b-66bcd7b612c5.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 Bayes' Rule\n",
    "p1 :\n",
    "- 종종 ${P(y|x)}$는 알고 있을 때, ${P(x|y)}$를 알아야하는 상황이 발생\n",
    "- 다행히도 ${P(x)}$또한 알고 있을 때, '**Bayes' rule**'을 적용하여 원하는 양을 계산할 수 있음\n",
    "\n",
    "$${P(x|y)=\\frac{P(x)P(y|x)}{P(y)}}$$\n",
    "\n",
    "- ${P(y)}$가 식에 나타나지만 주로 ${P(y)=\\Sigma_{x}P(y|x)P(x)}$를 계산하는데 쓰이므로, P(y)의 지식에서부터 시작할 필요 없음\n",
    "\n",
    "p2(**page 71**) :\n",
    "- Baye's rule은 조건 확률의 정의로부터 도출하기 간단하지만, 많은 텍스트들이 언급했기 때문에 이 식의 이름을 아는 것이 필요\n",
    "    - 이 식의 이름은 Reverned Thomas Bayes로 이 수식의 특별한 경우를 처음으로 발견한 사람의 이름임\n",
    "    - 위에 명시된 일반적인 버전은 Pierre-Simon Laplace가 독자적으로 개발함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 Technical Details of Continuous Variables (<span style=\"color:red\">PASS</span>)\n",
    "p1 : \n",
    "- continous random variable들과 probability density function들의 적절한 공식 이해를 위해 '**measure theory**'라고 알려진 수학의 한 분기로 probability theory 개발이 필요했음\n",
    "- measure theory는 이 책의 범위를 벗어나지만 간단히 measure theory가 사용된 문제들을 간단하게 그릴 수 있음\n",
    "\n",
    "p2 :\n",
    "- 3.3.2장에서, 집합 ${S}$의 연속적인 벡터 값 x의 확률은 집합 ${S}$에 대한 ${p(x)}$의 적분으로 주어짐\n",
    "- 집합 ${S}$의 몇 가지 선택은 역설을 불러올 수 있음\n",
    "    - ${p(x \\in S_1)+p(x \\in S_2)>1}$, ${S_1\\cap S_2=0}$을 만족하는 두 집합 ${S_1, S_2}$를 생성할 수 있음\n",
    "    - 예를 들어, fractal모양의 집합이나 유리수 집합을 변형시킴으로써 정의되는 집합을 만듦으로써 이 두 집합은 일반적으로 실수의 무한한 정확성의 heavy use를 일으키면서 생성됨\n",
    "- measure theory의 핵심 contributions 중 하나는 역설을 마주치지 않는 확률을 계산할 수 있는 집합들의 집합 특징을 제공하는 것임\n",
    "- 본 책은 상대적으로 단순한 서술로 집합들을 통합만 하여 이런 관점에서의 measure theory는 관련있는 문제가 되지 않을 것임\n",
    "    \n",
    "p3.\n",
    "- 원래 목적을 위해 measure theory는 ${R^n}$집합의 대부분의 점들에 적용되는 이론들을 묘사하는데 더 유용하지만 몇 corner case(정상 범위 외에서만 발생하는 문제)에는 적용하면 안됨\n",
    "- measure theory는 점들의 집합이 무시할만큼 작다는 것을 설명하는 철저한 방법을 제공\n",
    "- 그러한 집합은 '**measure zero**'를 가짐\n",
    "- 이 개념을 다루진 않겠음\n",
    "- 이 책에서 다루고자 하는 영역에서 measure zero는 측정하고자 하는 공간에서 어떠한 부피도 차지하지 않는 다는 직관만 있으면 이해하는데 충분\n",
    "    - 예를 들어, ${R^2}$에서 한 선이 measure zero를 가지는데 반면 채워진 다각형은 positive measure을 가짐\n",
    "    - 비슷하게, 각 점은 measure zero를 가짐\n",
    "- 각각 measure zero를 갖는 셀 수 있는 많은 집합체 또한 measure zero를 가짐 (그러므로 모든 유리수 집합도 measure zero를 가짐)\n",
    "\n",
    "p4.\n",
    "- 또다른 measure theory의 유요한 용어는 '**almost everywhere**'\n",
    "- almost everywhere을 갖는 특성은 measure zero의 집합을 제외한 모든 공간에서 유지됨\n",
    "- 왜냐하면 이 예외사항들은 무시해도 될 정도의 공간을 차지하기 때문에 많은 응용들에서 무시될 수 있음\n",
    "- 몇 중요한 확률 이론 결과들은 모든 이산 값에 대해 유지되지만 연속적인 값들에 대해서는 \"almost everywhere\"만 적용됨\n",
    "\n",
    "p5.\n",
    "- 연속 변수들의 또 다른 기술적 detail은 연속 랜덤 변수들을 다루는 것과 연관되는데 이는 서로의 결정론적 함수\n",
    "- 두 랜덤 변수 x, y를 가정했을 때 ${y=g(x)}$의 관계로 함수 ${g}$는 역수를 취할 수 있으며 연속적이고 미분가능한 변환임\n",
    "- ${p_y(y)=p_x(g^{-1}(y))}$를 기대할 수도 있지만 이건 다루는 범위가 아님\n",
    "\n",
    "p6.\n",
    "- 간단한 예시로, 스칼라 랜덤 변수 x, y가 있다고 가정\n",
    "- ${y=\\frac{x}{2}}$, ${x~U(),1)}$\n",
    "- ${p_y(y)=p_x(2y)}$법칙을 사용하면 ${p_y}$는 1이 되는 범위 ${[0,\\frac{1}{2}]}$를 제외한 모든 범위에서 0이 될 것임\n",
    "- 이는 수식으로\n",
    "\n",
    "$${\\int{p_y(y)dy}=\\frac{1}{2}}$$\n",
    "\n",
    "- 이는 확률 분포의 정의를 위반하는 자주 있는 실수\n",
    "- 이러한 접근의 문제점은 함수${g}$에 의한 공간 왜곡을 염두에 두지 않은 접근임\n",
    "- x의 확률이 무한소로 작아지는 구간에서 질량 ${\\delta x}$는 ${p(x)\\delta x}$에 의해 주어짐\n",
    "- g는 공간을 확대 및 축소할 수 있기 때문에 x 공간에서 x 주변의 무한소 질량은 y 공간의 다른 질량을 가질 것\n",
    "\n",
    "\n",
    "p7.\n",
    "- 문제 해결을 위해 스칼라 경우로 돌아감\n",
    "- 다음과 같은 성질을 만족해야함\n",
    "\n",
    "$${|p_y(g(x))dy|=|p_x(x)dx|}$$\n",
    "\n",
    "- 수식을 정리하면\n",
    "\n",
    "$${p_y(y)=p_x(g^{-1}(y))|\\frac{\\partial x}{\\partial y}|}$$\n",
    "\n",
    "- 또는 동등하게\n",
    "\n",
    "$${p_x(x)=p_y(g(x))|\\frac{\\partial g(x)}{\\partial x}|}$$\n",
    "\n",
    "- 높은 차원에서 이 편미분이 '자코비안 행렬(**Jacobian matrix**)'의 결정자를 생성-${J_{i,j}=\\frac{\\partial x_i}{\\partial y_i}}$\n",
    "- 즉 실제 값 x, y는\n",
    "\n",
    "$${p_x(x)=p_y(g(x))|det(\\frac{\\partial g(x)}{\\partial x})|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.13 Information Theory\n",
    "p1 (**page 73**):\n",
    "+ 신호에 얼마나 많은 정보가 있는지 정량화 하는 수학 분야\n",
    "+ 원래는 통신 잡음이 많은 무선 통신에서 이산 알파벳 메시지를 보내는 것을 연구하기 위해 만들어짐\n",
    "+ 다양한 인코딩 체계를 사용하여 특정 확률 분포에서 샘플링 된 메시지의 예상 길이를 계산하는 방법\n",
    "\n",
    "p2:\n",
    "+ 정보 이론의 기본은 \"일어날 수없는 사건\"이 발생했다는 것을 배우는 것이 \"당연한 사건\"이 발생했다는 것을 배우는 것보다 더 유익하다는 것이다.\n",
    "+ 예를 들어, \"오늘 아침 해가 뜬다\" 라는 메시지는 보낼 필요가 없을 정도로 유익하지 않지만\"오늘 아침 일식이 있었다\"는 메시지는 매우 유익하다.\n",
    "\n",
    "p3:\n",
    "+ 정보이론은 이러한 직관적인 것을 공식화하는 방식으로 정보를 정량화 하고자 함\n",
    "+ 1. 당연하게 발생하는 이벤트는 적은 정보를 지녀야 하며, 너무나 당연하게 발생하는 이벤트는 어떠한 정보도 없어야 함\n",
    "+ 2. 드물게 발생하는 이벤트는 더 귀한 정보를 가짐\n",
    "+ 3. 독립적인 이벤트는 추가정보가 있어야 함\n",
    "    - 예를들어, 동전을 2번 던졌을 때 앞면이 2번 나온 사건에 대한 정보는\n",
    "    - 동전을 1번 던졌을 때 앞면이 1번 나온 사건의 정보보다 2배 더 많아야 함\n",
    "\n",
    "p4:\n",
    "+ 이러한 세 가지 조건을 만족시키기 위해, $\\mathrm{x} = x$인 이벤트에 대한 **self-information**을 다음과 같이 정의함\n",
    "\n",
    "$$I\\left( x \\right) =-\\log { P(x) }$$\n",
    "\n",
    "+ 여기서 로그는 밑이 $e$ 인 자연로그임\n",
    "    - 자연로그로 표현된 정보량 $I\\left( x \\right) $ 는 units of **nats** 라고 부름\n",
    "    + 1 nats은 확률 $1/e$를 관찰함으로써 얻은 정보의 양을 나타냄\n",
    "+ 만약, 로그의 밑이 2 인 경우에 그 정보량 $I\\left( x \\right) $의 단위는 섀년(Shannon) 또는 비트(bit) 라고 부름\n",
    "\n",
    "p5 (**page 74**):\n",
    "+ 이산적으로 발생하는 이벤트는 일부 정보 손실이 있을 수 있음\n",
    "+ 예를 들어, unit density를 갖는 이벤트는, 발생되는 것이 보장되지 않음에도 불구하고 0의 정보량을 갖음\n",
    "\n",
    "p6:\n",
    "+ self-information은 오직 단일 결과(outcome)에 대해서만 다룸\n",
    "+ 섀넌 엔트로피(**Shannon entropy**)를 이용하면 모든 probability distribution의 불확실성의 양을 정량화할 수 있음\n",
    "+ 어떤 확률분포 $P$에 대한 섀넌 엔트로피 :\n",
    "\n",
    "$$\n",
    "H\\left( x\\right) ={ E }_{ X\\sim P }\\left[ I\\left( x \\right)  \\right] =- \\mathbb{ E }_{ X\\sim P }\\left[ \\log { P(x) }  \\right]\n",
    "$$\n",
    "\n",
    "+ 섀년 엔트로피는 발생 가능한 모든 결과의 가지 수에 밑이 2인 로그를 취한 것과 같다.\n",
    "+ 앞, 뒤 면이 다른 동전 뒤집기 처럼 동등한 확률을 가진 1/2인 경우는 높은 엔트로피를 가지며, 앞면이 두 개인 동전 뒤집기의 경우는 앞면만 나올 확률이 자명하기 때문에 엔트로피가 낮다. (사실상 0임)\n",
    "+ $ \\text{x} $ 가 continous일 경우, 섀넌 엔트로피가 아닌 **differential entropy**라 함\n",
    "\n",
    "p7:\n",
    "+ 하나의 random variable $ \\text{x} $에 대해 서로 다른 데이터의 분포 $P(x)$와 $Q(x)$가 있는 경우, 쿨백-라이블러 발산(**Kullback-Leibler divergence**, KLD, KL 발산)을 이용해 두 분포가 얼마나 다른지 측정할 수 있다.\n",
    "\n",
    "$${ D }_{ KL }\\left( P||Q \\right) =\\mathbb{ E }_{ x\\sim P }\\left[ \\log { \\frac { P\\left( x \\right)  }{ Q(x) }  }  \\right]= \\mathbb{ E }_{ x\\sim P }\\left[ \\log P(x) - \\log Q(x)  \\right]$$\n",
    "\n",
    "p8(<span style=\"color:red\">PASS</span>):\n",
    "+ discrete variable의 경우, 확률 분포 $Q$에서 도출 된 메시지 길이를 최소화할 때, 확률 분포 $P$에서 가져온 기호를 포함하는 메시지를 보내는 데 필요한 추가 정보임\n",
    "\n",
    "p9:\n",
    "+ KL divergence는 non-negative\n",
    "+ KL divergence = 0\n",
    "    - $ P $와 $ Q $가 완전하게 동일한 분포일 때(discrete variable)\n",
    "    - $ P $와 $ Q $가 \"almost everywhere\"에서 동일한 분포일 때(continous variable)\n",
    "+ KL divergence는 non-negative이고, 두 분포의 차이를 측정함\n",
    "    - 개념적으로 두 분포간의 거리를 측정하는 것으로 생각할 수 있음\n",
    "    - 반면, 실제 거리를 측정하는 것과는 거리가 있음\n",
    "        - symmetric하지 않기 때문 : $ D_{KL}(P||Q) \\neq D_{KL}(Q||P) $\n",
    "        - 즉, 측정 시 $ D_{KL}(P||Q) $을 사용할지, $ D_{KL}(Q||P) $를 사용할지 고려해야 함\n",
    "\n",
    "p10 (**page 75**):\n",
    "+ **cross-entropy** : KL divergence와 밀접하게 관련된 quantity $ H(P, Q) = H(P) + D_{KL}(P||Q) $\n",
    "\n",
    "$$H\\left( P,Q \\right) =\\mathbb{E}_{ X\\sim P }\\left[ -\\log { Q(x) }  \\right]$$\n",
    "\n",
    "+ $Q$에 대한 크로스 엔트로피를 최소화 하는 것은 다른 항에 영향을 미치지 않기 때문에 쿨백-라이블러 발산을 최소화 하는 것과 같다. \n",
    "\n",
    "p12:\n",
    "+ 종종 $ 0 \\log{0} $과 같은 표현이 나오는데, 일반적으로 정보이론에서는 이러한 표현은 $\\lim_{x \\to 0}{x}\\log{x}$ 로 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.14 Structured Probabilistic Models (<span style=\"color:red\">책으로 간략하게 설명하겠음</span>)\n",
    "\n",
    "p4:\n",
    "+ 기계학습 알고리즘은 많은 랜덤변수에 대한 확률 분포 표현을 이용한다.\n",
    "+ 단일 확률 분포를 사용하기에는 변수들의 관계를 나타내기 힘들다.\n",
    "\n",
    "p1 (**page77**):\n",
    "+ 단일 확률 분포를 사용하는 것 대신 확률 분포를 여러 factor로 나눈다\n",
    "+ 예를 들어,  a가 b의 값에 영향을 미치고 b의 값이 c의 값에 영향을 미치지만 a와 c가 b에 대해 독립적이라고 가정하면, 다음과 같이 나타내 수 있다.\n",
    "\n",
    "$$p(a, b, c) = p(a)p(b|a)p(c|b)$$\n",
    "\n",
    "p2:\n",
    "+ 이러한 분해는 확률 분포를 묘사하는데 필요한 매개변수의 수를 크게 줄일 수 있다.\n",
    "+ 더 적은 변수로 이러한 분해가 가능하면 확률 분포를 나타내는 비용이 줄어든다.\n",
    "\n",
    "p3:\n",
    "+ 이러한 분해는 그래프로 그려질 수 있으며, 우린 이 것을 구조화된 확률 모델(structured probabilistic model) 또는 그래프 모델(graphical model)이라 부른다.\n",
    "\n",
    "p4:\n",
    "+ 그래프 모델은 Directed Graphical Model와 Undirected Graphical Model 으로 나뉜다.\n",
    "\n",
    "p5:\n",
    "+ Directed Graphical Model은 순서가 지정되며, 화살표로 표시된다. (계층적 구조로 볼 수 있음)\n",
    "+ 각 노드는 곱 연산으로 이루어지며, $i$ 번째 까지의 분포 $p$는 다음과 같이 표기된다.\n",
    "\n",
    "$$p(x) = \\prod_{i} p(x_i|Pa_{\\mathcal{G}}(x_i))$$\n",
    "\n",
    "+ 이러한 형태의 그래프를 베이지안 네트워크라 부른며, 예시는 다음과 같다.\n",
    "![LSGfig_3_1](https://user-images.githubusercontent.com/52661707/75842528-dc33e700-5e13-11ea-8b63-822d0cc18d70.PNG)\n",
    "\n",
    "p1 (**page78**):\n",
    "+ Undirected Graphical Model은 화살표가 없는 그래프를 사용하여 분포를 나타낸다.\n",
    "+ directed와 다르게 순환 종속성을 나타낼 순 있지만, 유도 종속성은 나타낼 수 없다.\n",
    "> + Clique : 그래프 상 완벽한 부분\n",
    "> + 완벽한 부분 : 모든 노드들이 연결 되어 있는 경우\n",
    "> + 예시\n",
    "![LSGadd_3_](https://user-images.githubusercontent.com/52661707/75844529-a2fe7580-5e19-11ea-8ba3-e0cf7cdad05f.PNG)\n",
    "+ 하나의 Clique를 $\\mathcal{C}$라고 나타내자.\n",
    "+ $i$ 번째 \\mathcal{C}의 누적 분포 함수를 $\\phi^{(i)}(\\mathcal{C}^{(i)})$ 라고 할 수 있다.\n",
    "\n",
    "p2:\n",
    "+ 랜덤 변수 구성 확률은 모든 누적 분포 함수의 곱으로 나타내진다.\n",
    "+ 이 곱의 합이 1이라는 보장이 없기 때문에 정규화 상수 $Z$로 나누어야 한다.\n",
    "+ 즉, 다음과 같은 식이 도출된다.\n",
    "\n",
    "$$p(x) = \\frac{1}{Z} \\prod_{i} \\phi^{(i)}(\\mathcal{C}^{(i)})$$\n",
    "\n",
    "+ 이러한 형태의 그래프를 마르코프 랜덤 필드라 부르며, 예시는 다음과 같다.\n",
    "![LSGfig_3_2](https://user-images.githubusercontent.com/52661707/75845343-23be7100-5e1c-11ea-8d82-6b9a6211a7af.PNG)\n",
    "\n",
    "p1 (**page79**):\n",
    "+ 3장에 나온 확률 모델들을 이해 한다면, 이 책을 보는데 어려움은 없을\n",
    "\n",
    "p2:\n",
    "+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
