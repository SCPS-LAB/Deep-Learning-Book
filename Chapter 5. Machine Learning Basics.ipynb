{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5 Machine Learning Basics\n",
    "\n",
    "p1 (**page98**) :\n",
    "+ 이번 장은 딥러닝 알고리즘에 큰 영향을 준 \"전통적인 머신 러닝 기술\"에 대한 내용을 다룬다.\n",
    "\n",
    "p2 :\n",
    "+ 이 장에서는\n",
    "> + 학습 알고리즘(learning algorithm)이란 무었인지에 대한 정의하고, 그 예로써 선형 회귀(Linear regression)를 설명한다.\n",
    "> + 그 다음, 훈련 데이터 피팅(fitting)과 패턴찾기(pattern finding)의 차이점을 설명한다.\n",
    "> + 하이퍼 파라미터와 이를 어떻게 조절하는지에 대해 설명한다.\n",
    "\n",
    "+ 기계학습은 복잡한 함수를 통계적으로 추정하기 위해 컴퓨터를 사용한다는 것과, 그 함수들을 증명하기 위한 신뢰구간 해석에 대한 중요성이 감소된(???) 통계의 한 형태이다.\n",
    "+ 우리는 통계학에 대해 빈도 추정(Frequentist estimators)와 베이지안 추론(Bayesian inference)을 이용하여 접근한다.\n",
    "\n",
    "+ 기계학습은 지도학습과 비지도학습으로 나눌 수 있으며, 각 분야에 대해 간단한 예를 보여준다.\n",
    "+ 대부분의 딥러닝 알고리즘에서 사용하는 확률적 경사 하강법(Stochastic gradient descent)에 대해 소개한다.\n",
    "+ 기계학습 알고리즘을 만들기 위해 최적화 알고리즘(Optimization algorithm), 비용 함수(Cost function), 모델과 데이터셋과 같은 알고리즘의 구성 요소들을 어떻게 결합할지 설명한다.\n",
    "+ 5.11절 에서는 전통적인 머신 러닝의 일반화 능력 제한에 관해 설명한다.\n",
    "> 머신러닝은 이 세상 모든 현상에 대해 일반화 할 수 없기 때문에 제약을 걸어놓고, 한정된 도메인에서만 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Learning Algorithms\n",
    "\n",
    "p1 (**page99**):\n",
    "+ 기계학습 알고리즘은 데이터로부터 학습(learn)하는 알고리즘 이다.\n",
    "+ 학습의 의미는\n",
    "> + “A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$.”Mitchell (1997)\n",
    "+ 우리는 아주 다양한 경험 $E$, 작업 $T$, 측정치 $P$를 상상할 수 있으며, 이러한 개념에 대해 절대적인 공식은 존재하지 않지만, 각각의 $E$, $T$, $P$에 대한 직관적인 설명과 예시를 들 것 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1 The Task, $T$\n",
    "\n",
    "p1 :\n",
    "+ 기계학습을 통해 기존의 프로그램(fixed programs; 고정된 프로그램)이 해결하지 못하는 \"과제\"를 해결할 수 있다.\n",
    "+ 기계학습을 만드는 것은 우리가 가진 지능을 이해하는 것을 기반하기 때문에 매우 흥미롭다. (사족?)\n",
    "\n",
    "p2 :\n",
    "+ 학습과정 자체가 \"작업\"은 아니다.\n",
    "+ 학습은 작업을 수행할 수 있는 능력은 얻는 수단 이다.\n",
    "\n",
    "p3 :\n",
    "+ 기계학습 \"작업\"은 주어진 예제를 처리하는 방법과 관련하여 설명 된다. \n",
    "+ 기계학습이 \"작업\"을 처리하고자 어떤 feature를 기준으로 구분하는지에 따라 방법이 나뉜다.\n",
    "+ 이러한 feature를 벡터 $x \\in \\mathbb{R}^n$ 로 표현하며, 각 항목 $x_i$ 는 다른 feature 이다.\n",
    "+ 예를 들어 형태는 이미지의 feature는 이미지의 픽셀 값으로 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p4 (**page100**) :\n",
    "+ 가장 일반적인 머신 러닝 작업에는 다음이 포함됩니다.\n",
    "\n",
    "p5 : Classification\n",
    "> + 입력에 대해 $k$개의 범주 중 하나를 지정하는 작업\n",
    "> + 예) 이미지로 0~9의 숫자가 적힌 입력값에 대해 픽셀값을 식별하여 0~9 의 값 중 하나를 지정하는 작업\n",
    "\n",
    "p6 : Classification with missing inputs\n",
    "> + 입력값의 벡터의 요소 중 어떤 값이 측정되지 않았을 때 missing data라고 함\n",
    "> + 이런 경우에도 기계학습 알고리즘은 동작할 수 있도록 일련의 기능을 학습해야 한다.\n",
    "> + 이런식으로 입력값이 누락되는 경우에도 동작할 수 있도록 학습 과정에서 몇몇 변수들을 누락시키고 학습을 진행시키면, missing inputs이 발생해도 정상적인 분류를 할 수 있다. (Dropout에 대해 너무나도 어렵게 설명함)\n",
    "> + [++참고](https://ourcstory.tistory.com/141)\n",
    "\n",
    "p7 Regression (**page101**) : \n",
    "> + 입력값에 따라 실수 범위에서 결과값을 예측\n",
    "> + 출력 형식이 다르다는 것만 빼면 일반 Classification과 비슷(실수범위 결과 / 정수범위 결과)\n",
    "> + 예를 들어 유가 증권의 가격 예측에 사용될 수 있음\n",
    "\n",
    "p8 Transcription : \n",
    "> + 언어와 관련된 다른 형식의 데이터(이미지에 있는 글자들, 음성 메시지)를 ASCII 문자로 변환(또는 다른 문자 형식)\n",
    "> + 느리게 말하건 빨리 말하건 정확하게 단어를 잡아낼 수 있어야함 (heeellllllllloooo -> hello)\n",
    "\n",
    "p9 Machine translation : \n",
    "> + 기계 번역은 특정 나라의 언어로 작성 된 문장을 다른 나라의 언어로 문장을 다시 만드는 것 이다.\n",
    "\n",
    "p10 Structured output : \n",
    "> + 구조화 예측은 결과값을 정수 범위에서 선택하거나 실수범위에서 선택하는게 아닌 구조화 된 객채로써 결과를 내는 기계학습 기술 이다.\n",
    "> + 이전에 설명 했던 Transcript와 Translate가 이에 속하며, 이미지를 문장으로 설명해 주는 것도 포함한다.\n",
    "\n",
    "p11 Anomaly detection (**page102**) : \n",
    "> + 이상 탐지는 주어지는 데이터들을 비교하여 특출난 패턴을 가지는 데이터를 골라 내는 것을 말한다.\n",
    "> + 예를 들어 신용카드의 소비 패턴을 분석하여 도난 카드를 감지할 수 있다.\n",
    "\n",
    "p12 Synthesis and sampling : \n",
    "> + 합성 및 샘플링은 학습한 데이터를 기반으로 전에 없던 새로운, 학습데이터와 비슷한, 데이터를 생성 해 내는 것을 말한다.\n",
    "> + 구조화 예측과 비슷 하지만, 합성 및 샘플링에는 정답이 없기 때문에 더 자유롭다.\n",
    "\n",
    "p13 Imputation of missing values : \n",
    "> + 손실 값 산입은 불완전한 데이터가 있을 때, 표준이나 다른 대표성 있는 데이터를 활용하여 대페될 수 있는 값으로 계산하여 입력하는 것을 말한다.\n",
    "> + 기존의 산입 알고리즘은 표준이나 대표성 있는 데이터가 필요했지만 이를 기계학습으로 대체할 수 있다.\n",
    "\n",
    "p14 Denoising (**page103**) :\n",
    "> + 데이터가 오염 되었을 경우 원본 데이터를 복구 하는 것을 말한다.\n",
    "> + 오염되지 않은 데이터 $x \\in \\mathbb{R}^n$ 에서 오염된 데이터 $\\tilde{x} \\in \\mathbb{R}^n$ 를 만들고 입력값을 $\\tilde{x}$으로, 출력 값을 $x$로 하여 학습 시킨다. \n",
    "\n",
    "p15 Density estimation or probability mass function estimation :\n",
    "> + 확률 밀도 추정 문제에서 기계학습 알고리즘은 $p_{model} : \\mathbb{R}^n \\to \\mathbb{R}$ 를 학습한다.\n",
    "> + $p_{model} (x)$은 $x$가 연속적인 경우 확률 밀고 함수가 되고, 이산적일 경우 확률 질량 함수가 된다.\n",
    "> + 주어진 예제에 대해 클러스터링 한 부분이 최대한 덜 겹치도록 결과가 나와야한다.\n",
    "> + 하지만 완벽한 확률 밀도 함수(또는 확률 질량 함수) $p(x)$를 구하기 힘들기 때문에 이 방법으로 모든 것을 해결할 수는 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.2 The Performance Measure, $P$\n",
    "\n",
    "p1 :\n",
    "+ 기계학습 알고리즘의 평가를 위해 성능 평가 메트릭을 만들어야 하며, 작업 $T$에 따라 성능 평가 방법이 달라진다.\n",
    "\n",
    "p2 :\n",
    "+ classification, classification with missing inputs와 transcription의 경우 모델의 정확도를 측정한다.\n",
    "+ 정확도는 단순히 n번 실행 했을 때 m번 정답을 맞추면 n/m으로 구할 수 있다.\n",
    "+ 이러한 방법은 밀도 추정의 경우에는 전혀 쓸모가 없다.\n",
    "+ 그 대신 로그 확률(log-probability)을 이용해 성능평가를 할 수 있다.\n",
    "\n",
    "p3 (**page104**) :\n",
    "+ 일반적으로 한 도메인에서 훈련된 기계학습 알고리즘은 훈련데이터에 사용되었던 이외의 동일한 도메인 데이터에 대해 얼마나 잘 동작하는지 보여줄 수 있어야 한다.\n",
    "+ 그렇기 때문에 결과를 낼 때는 훈련 데이터에 사용되었던 데이터 이외의 것을 가지고 최종 정확도를 도출해 낸다.\n",
    "\n",
    "p4 :\n",
    "+ 성능 측정 방법은 많기 때문에 가장 효과적으로 설계한 기계학습의 퍼포먼스를 나타낼 수 있는 성능 평가 메트릭을 고르기는 쉽지 않다.\n",
    "\n",
    "p5 :\n",
    "+ 또한 Regression을 수행할 때 정확도가 아주 높지만 몇몇 오차가 매우 큰 차이가 나는 경우와 정확도가 매우 높진 않지만 대체로 결과의 분포가 비슷한 경우 단순 정확도에 따라 모델을 평가 할지는 선택하기 어렵다.\n",
    "\n",
    "p6 : \n",
    "+ 또 다른 경우에, 밀도 추정 문제에 있어서 정확히 한 지점에 해당하는 확률을 구할 수 없으며, 적합한 근사치를 직접 설계해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.3 The Experience, $E$\n",
    "\n",
    "p1 : \n",
    "+ 머신러닝은 지도학습과 비지도학습으로 나뉜다.\n",
    "\n",
    "p2 : \n",
    "+ ????? (5.1.1에 있는 데이터셋을 때때로 호출할 것 이다???) \n",
    "\n",
    "p3 (**page105**) :\n",
    "+ 가장 오래된 데이터세트 중 하나는 iris 데이터 세트 이다.\n",
    "\n",
    "p4 :\n",
    "+ **Unsupervised learning algorithms**(비지도학습)은 많은 feature를 포함하는 데이터셋을 학습하고 이 데이터셋에서 유효한 feature를 학습한다.\n",
    "+ 암시적으로 이 데이터셋을 생성하는 확률 분포를 학습하는 것이 목적이다.\n",
    "+ 입력받은 데이터의 feature에 따라 클러스터링 하는 작업을 한다.\n",
    "\n",
    "p5 :\n",
    "+ **Supervised learning algorithms**(지도학습) 은 각 데이터는 레이블링 되어있어 레이블을 기준으로 feature를 뽑아 내고, 다른 입력에 대해서 가까운 레이블을 선택하는 작업을 한다.\n",
    "\n",
    "p6 :\n",
    "+ 대략, 비지도학습은 무작위 벡터 $X$를 학습하여 그 데이터의 확률 분포 $p(x)$를 추정하는 반면, 지도학습은 레이블 $y$가 있는 벡터 $X$를 학습하여 $p(x|y)$를 추정한다.\n",
    "\n",
    "p7 :\n",
    "+ 비지도학습과 지도학습은 공식적인 용어가 아니며, 종종 그 구분이 흐려질 때도 있다.\n",
    "+ 예를 들어 확률의 연쇄법칙에 따라 결합 분포(Joint distribution)는 다음과 같이 표현될 수 있다.\n",
    "\n",
    "$$p(x) = \\prod_{i=1}^n p(x_i|x_1, ... , x_{i-1})$$\n",
    "\n",
    "p8 :\n",
    "+ 이 분해는 레이블되지 않은 데이터를 $n$개의 레이블된 데이터로 분할하여 해결할 수 있다는 것을 보여준다.\n",
    "+ 또한 다음의 추론을 통해 결합 분포 $p(x,y)$를 학습하고 $p(y|x)$를 구할 수 있다.\n",
    "\n",
    "$$p(y|x) = \\frac{p(x,y)}{\\Sigma_{y'}p(x,y')}$$\n",
    "\n",
    "p9 (**page106**):\n",
    "+ 비지도학습이나 지도학습이 완벽하진 않지만 널리 사용된다.\n",
    "\n",
    "p10 :\n",
    "+ 여러 변형이 있으며, 반지도학습(semisupervised learning)의 경우 일부는 레이블이 있는 데이터를 보함하고 일부는 그렇지 않다.\n",
    "\n",
    "p11 :\n",
    "+ **reinforcement learning**(강화학습)은 환경과 상호작용 하면서 학습 모델에 피드백 루프를 형성한다.\n",
    "\n",
    "p12 :\n",
    "+ 대부분의 머신러닝은 단순히 데이터세트를 정적으로 받아들여 학습하기만 한다.\n",
    "+ 데이터 세트는 훈련 예시의 모음이며, 다시 말하면 feature set 이라고 볼 수 있다.\n",
    "\n",
    "p13 :\n",
    "+ 데이터셋을 표현하는데 계획 행렬(Design matrix)를 이용할 수 있다.\n",
    "+ 예를 들어 iris는 4개의 feature와 150개의 데이터로 이루어져 잇는데 이를 $X \\in R^{150×4}$으로 나타낼 수 있다.\n",
    "+ 여기서 $X_{i,1}$은 $i$번째 식물의 첫 번째 feature(꽃턱의 길이)이고, $X_{i,2}$는 $i$번째 식물의 두 번째 feature(꽃턱의 너비)이다.\n",
    "\n",
    "p14 : \n",
    "+ 데이터셋을 계획행렬로 표현하기 위해서는 모든 벡터의 크기가 동일해야 하지만, 현실에서는 그렇지 않다.\n",
    "+ 예를 들어 픽셀의 수가 다른 이미지가 있을 수 있으며, 이러한 경우 ${x^{(1)},x^{(2)},...,x^{(m)}}$으로 표현할 수 있으며, $x^{(i)}$와 $x^{(j)}$는 같은크기를 지니고있지 않다는 것을 의미한다.\n",
    "\n",
    "p15 (**page107**) :\n",
    "+ 지도학습은 데이터 뿐만 아니라 각 데이터에 매칭되는 레이블도 포함되어야 한다.\n",
    "+ 일반적으로는 레이블에는 숫자를 대입하여 사용한다. (고양이 : 0, 개 : 1, ...)\n",
    "\n",
    "p16 :\n",
    "+ 레이블의 구분은 단순 숫자 이상일 수도 있다.\n",
    "+ 기계 번역의 경우에는 각각의 단어들은 숫자가 아닌 또다른 단어로 레이블링 된다.\n",
    "\n",
    "p17 :\n",
    "+ 지도학습, 비지도학습에 대한 공식적인 정의가 없는 것 처럼 데이터셋의 분류나 경험에 대한 엄격한 분류는 정의하고 있지 않다.\n",
    "+ 새로운 응용 프로그램을 위해 언제든 자신만의 구조(structure)를 설계할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.4 Example: Linear Regression\n",
    "\n",
    "p1 :\n",
    "+ 우리는 기계학습의 동작을 선형 회귀(Linear refression)를 예로 들어 설명한다.\n",
    "\n",
    "p2 :\n",
    "+ 선형 회귀는 벡터 $x \\in \\mathbb{R}^n$를 입력으로 취하고, 스칼라 $y \\in \\mathbb{R}$의 실수값을 출력하는 시스템이다.\n",
    "+ 입력값 $x$의 정답이 결과값 $y$인 경우, 선형 회귀가 예측한 결과값을 $\\widehat{y}$라고 하면 출력은 다음과 같이 정의할 수 있다.\n",
    "\n",
    "$$\\widehat{y} = w^{top}x$$\n",
    "\n",
    "+ 여기서 $w$는 $w \\in \\mathbb{R}^n$를 만족하는 매개변수 이다.\n",
    "\n",
    "p3 :\n",
    "+ 매개변수는 시스템 동작을 제어할 수 있다.\n",
    "+ 위 식에 따라 입력벡터 $x$의 모든 요소(백터의 스칼라값들)는 매개변수 벡터 $w$의 모든 요소와 곱해져 더해진다.\n",
    "+ 이 $w$를 예측 결과값에 영향을 미치는 \"가중치\"라고 볼 수 있다.\n",
    "\n",
    "p4 (**page108**):\n",
    "+ 따라서 선형 회귀는 작업($T$)에 대해, $\\widehat{y} = w^{top}x$를 출력하여 $x$에서 $y$를 예측한다는 정의를 가질 수 있다.\n",
    "+ 이제 다음으로 성능 측정($P$)를 정의해야 한다.\n",
    "\n",
    "p5 :\n",
    "+ 학습데이터가 아닌, 성능 평가를 위한 m개의 데이터가 있다고 가정하자.\n",
    "+ 이 데이터들은 평가를 위한 \"데스트셋\"이라 말한다.\n",
    "+ 입력 데이터의 행렬을 $X^{(test)}$라 하고, 회귀 목표 벡터를 $y^{(test)}$라 하자.\n",
    "\n",
    "p6 :\n",
    "+ 모델의 성능을 측정하는 방법으로 평균 제곱 오차(Mean Squared Error : MSE)를 구하는 것이 있다.\n",
    "+ 선형 회귀 모델이 예측한 결과값 $\\widehat{y}^{(test)}$를 예측 한다면 다음과 같은 수식으로 표현할 수 있다.\n",
    "\n",
    "$$MSE_{test} = \\frac{1}{m}\\sum_{i} (\\widehat{y}^{(test)}-y^{(test)})^{2}_{i}$$\n",
    "\n",
    "p7 :\n",
    "+ 이 수식에서 직관적으로 예측값 $\\widehat{y}^{(test)}$와 결과값 $y^{(test)}$이 같다면 $MSE$는 0이 된다는 것을 확인할 수 있다.\n",
    "\n",
    "p8 :\n",
    "+ 벡터 관점으로 보았을 때 $\\widehat{y}^{(test)}$와 $y^{(test)}$의 유클리드 거리가 증가함에 따라 오차($MSE$)가 커진다는 것을 확인할 수 있다.\n",
    "\n",
    "p9 :\n",
    "+ 기계학습 알고리즘에서 훈련세트($X^{(train)}, y^{(train)}$)를 학습하여 경험($E$)를 얻을 수 있을 때 $MSE_{(test)}$를 줄이는 쪽 으로 $w$를 조절하는 알고리즘을 설계해야 한다.\n",
    "+ 직관적으로 $MSE_{(test)}$를 줄이기 위해서는 학습단계에 있는 $MSE_{(train)}$를 줄이면 된다.\n",
    "\n",
    "p10 :\n",
    "+ $MSE_{(train)}$를 최소화 한다는 것은 기울기가 0인 부분을 찾는 것 이며, 우리는 간단히 다음과 같은 식을 이용해서 찾을 수 있다.\n",
    "\n",
    "$$\\triangledown_{w}MSE_{train} = 0$$\n",
    "$$\\Rightarrow \\triangledown_{w} ||\\widehat{y}^{(train)} - y^{(train)}||^2_2 = 0$$\n",
    "+ 여기서 $\\widehat{y}^{(train)}$는 $X^{(train)}w$으로 표현할 수 있으므로,\n",
    "$$\\Rightarrow \\frac{1}{m} \\triangledown_{w}||X^{(train)}w - y^{(train)}||^2_2$$\n",
    "+ $m$은 상수이기 때문에 무시될 수 있고(양 변에 $m$을 곱함) 벡터의 곱셈공식으로 인해 다음과 같이 정리된다.\n",
    "$$\\Rightarrow \\triangledown_{w}(X^{(train)}w - y^{(train)})^{\\top}(X^{(train)}w - y^{(train)}) = 0$$\n",
    "$$\\Rightarrow \\triangledown_{w}(w^{\\top}X^{(train)\\top}X^{(train)}w-2w^{\\top}X^{(train)\\top}y^{(train)}+y^{(train)\\top}y^{(train)}) = 0$$\n",
    "$$\\Rightarrow 2X^{(train)\\top}X^{(train)}w -2X^{(train)\\top}y^{(train)}=0$$\n",
    "+ w에 대해서 정리하면\n",
    "$$\\Rightarrow w = (X^{(train)\\top}X^{(train)})^{-1}X^{(train)\\top}y^{(train)}$$\n",
    "+ 로 정리 된다.\n",
    "\n",
    "p11 (**page109**) :\n",
    "+ 위와 같은 방정식으로 해를 수하는 시스템을 정규방정식(Normal equations)이라 한다.\n",
    "\n",
    "p12 :\n",
    "+ 선형 회귀에는 종종 추가적인 매개변수($b$)를 이용해 더 복잡한 모델을 나타내기도 한다.\n",
    "+ 매개변수 $b$를 추가한 다음의 수식 $\\widehat{y} = w^{top}x + b$ 은 여전히 선형 함수 이며, 이러한 변화는 아핀 변환(affine transformation)이라 한다.\n",
    "+ 아핀 변환을 한 아핀 함수(affine function)를 언급할 때 \"선형\"이라는 용어를 사용할 것 이다.\n",
    "\n",
    "p13 (**page110**) :\n",
    "+ 이렇게 추가된 $b$는 아핀 변환의 bias 매개변수라고 한다.\n",
    "+ 기존의 입력이 없는 경우에도($x = 0$인 경우) $b$가 되도록 \"편향\"한다는 관점에서 비롯되었다. \n",
    "\n",
    "p14 :\n",
    "+ 선형 회귀는 매우 간단한 알고리즘이지만, 학습 알고리즘이 어떻게 동작하는지 간단하게 살펴볼 수 있다.\n",
    "+ 다음 절 부터는 더 기본적인 알고리즘 설계의 기본 원리를 소개 하고, 더 복잡한 학습 알고리즘을 설계하는 것을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 5.2 Capacity, Overfitting and Underfitting\n",
    "p1 (**page110**) :\n",
    "  - 머신 러닝의 중점적인 도전 과제는 이미 학습된 모델만이 아닌 '새롭고, 이전에 학습되지 않은' inputs 에 대해 잘 동작해야하는 것\n",
    "  - 사전에 탐색되지 않은 inputs 에 대해 잘 동작하는 능력을 **generalization** 이라 함\n",
    "  \n",
    "p2 :\n",
    "  - 일반적으로, 머신 러닝을 학습시킬 때 학습 셋을 조정할 수 있고 이 때, 학습 셋에 대한 에러인 **training error** 를 줄이는 것이 목표\n",
    "  - 지금까지 나타낸 것은 단ㄷ순한 최적화 문제\n",
    "  - 머신 러닝과 최적화를 분리하는 것은 **generalization error**로 **test error**로도 불리는 오류를 최소화 하는 것\n",
    "  - generalization error는 새로운 입력의 예삭된 오차값이라 정의\n",
    "  - 서로 다른 가능한 입력들에 대한 예상이 이루어지는데 이 예상은 입력들의 분포로부터 주어지며 시스템이 실제로 마주칠 것으로 기대됨\n",
    "  \n",
    "p3 :\n",
    "  - 일반적으로 학습 셋으로부터 각각 수집한 예시들의 **test set**에 대한 성능을 측정함으로써 generalization error를 추정\n",
    "  \n",
    "p4 :\n",
    "  - 선형 회귀의 예를 들어 학습 에러를 최소화하여 모델을 학습\n",
    "  $${\\frac{1}{m^{(train)}}||X^{(train)}w-y^{(train)}||_{2}^2}$$\n",
    "  \n",
    "  \n",
    "  - 하지만 실제로 학습 오류를 다룸 ${\\frac{1}{m^{(test)}}||X^{(test)}w-y^{(test)}||_{2}^2}$\n",
    "  \n",
    "p5 :\n",
    "  - 학습 셋만을 관측할 때 test set에 대한 성능에 어떻게 영향을 끼칠 것인가?\n",
    "  - **통계 학습 이론**의 여러 답안\n",
    "  - 만약 학습, 테스트 셋이 무작위로 수집된다면 실제로 할 수 있는 것이 매우 적음\n",
    "  - 만약 학습, 테스트 셋이 어떻게 형성되는지에 대한 몇 가지 가정할 수 있다면?\n",
    "  \n",
    "p6 (**page111**) :\n",
    "  - 학습, 테스트 셋은 **data generating process** datasets에 대한 확률 분포에 의애 생성\n",
    "  - 일반적으로 **i.i.d. assumptions**이라 하는 가정 셋을 생성\n",
    "  - 이러한 가정은 각 데이터셋의 예시들이 서로 **독립적**이고 동일 확률 분포로부터 도출되어 학습, 테스트 셋이 **동일하게 분포**한 것을 의미\n",
    "  - 이 가정은 단 하나의 예시의 확률 분포와 데이터 생성 프로세스를 표현할 수 있게 해줌\n",
    "  - 동일한 분포는 모든 학습, 테스트 예시를 생성할 때 사용\n",
    "  - 이 공유되는 기저 분포 **data generating distribution** ${p_{data}}$\n",
    "  - 확률적 프레임워크, i.i.d. 가정으로 학습 오류와 테스트 오류 관계를 수식적으로 공부할 수 있음\n",
    "  \n",
    "p7 :\n",
    "  - 학습, 테스트 오류 사이에서 즉각적으로 볼 수 있는 것은 무작위로 선택된 모델의 예측 학습 오류 그 모델의 예측 테스트 오류와 동일\n",
    "  - 확률 분포 ${p(x,y)}$에서 학습, 테스트 셋을 생성하기 위해 반복적으로 샘플 추출\n",
    "  - 고정값 ${w}$에 대해 예측 학습 셋 오류는 예측 테스트 셋 오류와 정확히 동일한데 동일한 데이터셋 샘플링 과정으로 생성된 예측이기 때문\n",
    "  - 유일한 차이점: sample 추출한 데이터셋의 이름\n",
    "  \n",
    "p8 :\n",
    "  - 물론, 머신 러닝 알고리즘을 사용할 때, 파라미터를 시간에 앞서 고정하지 않은 다음 sample\n",
    "  - 학습 셋을 sample 하여 학습 셋 에러를 줄이기 위해 파라미터를 설정하고 테스트 셋 sample\n",
    "      - 예측 세트스 오류는 예측 학습 오류보다 크거나 같음\n",
    "      \n",
    "      \n",
    "  - 머신 러닝 알고리즘이 잘 동작하게 하는 특성\n",
    "      - 학습 오류 작게\n",
    "      - 학습, 테스트 오류의 차 작게\n",
    "  \n",
    "p9 :\n",
    "  - 위 두 특성은 머신 러닝의 두 중심적인 도전 과제들에 대응 **underfitting**, **overfitting**\n",
    "      - Underfitting: 모델이 학습 셋 오류가 충분히 낮지 않은 경우 발생\n",
    "      - Overfitting: 학습, 테스트 오류의 차이가 너무 큰 경우 발생\n",
    "  \n",
    "p10 :\n",
    "  - 모델의 **capacity** 를 변경함으로써 과적합, 과소적합 조절 가능\n",
    "  - 모델의 capacity는 매우 다양한 함수들에 맞기 위한 특성\n",
    "      - low capacity: 학습 셋에 맞추리 어려움\n",
    "      - high capacity: 학습 셋의 특성을 기억해 테스트 셋에 잘 동작하지 않아 overfit\n",
    "      \n",
    "p11(**page112**) :\n",
    "  - 학습 알고리즘의 capacity를 조절하는 방법: 알고리즘의 **hypothesis space**를 선택\n",
    "      - 상황에 따라 학습 알고리즘이 선택될 수 있는 함수 셋\n",
    "      \n",
    "      \n",
    "  - 예) 선형 회귀 알고리즘은 입력의 모든 선형 함수를 hypothesis space로 가짐\n",
    "      - 선형 회귀를 가설 공간에 선형 함수만을 갖는 것보다 다항식을 포함하기 위해 일반화\n",
    "      - 모델의 capcity 상승\n",
    "      \n",
    "p12 :\n",
    "  - 일차 다항식으로부터 이미 익숙한 선형 회귀식을 얻음 (+prediction)\n",
    "  $${\\hat{y}=b+wx}$$\n",
    "  \n",
    "  - ${x^2}$를 선형 회귀 모델에 주어진 또다른 특징으로 x에 대한 이차식\n",
    "  $${\\hat{y}=b+w_{1}x+w_{2}x^2}$$ee\n",
    "  \n",
    "  - 모델 입력: 이차 방정식, 출력: 파라미터의 선형 방정식\n",
    "      - 닫힌 형식으로 모델을 학습하기 위해 normal equations 사용 가능\n",
    "      \n",
    "      \n",
    "  - 계속해서 x의 거듭제곱을 더함 예) 9차 다항식\n",
    "  $${\\hat{y}=b+\\sum_{i=1}^9{w_{i}x^{i}}}$$\n",
    "  \n",
    "p13 :\n",
    "  - 머신 러닝 알고리즘은 일반저긍로 capacity가 요구되는 task의 true 복잡도가 적절하고 학습 데이터의 양이 적절할 때 가장 잘 동작\n",
    "  - capacity 부족 모델: 복잡한 일을 처리할 수 없음\n",
    "  - high capacity 모델: 복잡한 일을 처리할 수 있으나 필요 이상으로 capacity가 높을 때 overfit\n",
    "  \n",
    "p14 :\n",
    "  - fig 5.2 에 설명\n",
    "  \n",
    "  <img src=\"files/figure5_2.png\" width=800px;>\n",
    "  \n",
    "  \n",
    "  - 실제 underlying 함수가 이차방정식이 되는 문제에 맞추기 위한 노력으로 선형 방정식, 이차방정식, 9차 predictor를 비교\n",
    "  - 선형 방정식: true underlying 문제의 곡선을 잡지 못해 underfit\n",
    "  - 9차 predictor: 정확한 함수를 표현할 수 있으나 학습 examples보다 많은 파라미터가 있기 때문에 학습 points를 정확히 통과하는 무한히 많은 함수 또한 표현 가능\n",
    "      - 무수히 많은 서로 다른 solutions가 존재할 때 잘 일반화하는 solution을 고르기는 어려움\n",
    "      - 이차 모델은 완벽히 task의 true 구조에 매치되어 새로운 데이터 일반화가 잘 됨\n",
    "      \n",
    "p15 (**page113**) :\n",
    "  - 지금까지 모델의 capacity를 바꾸는 단 하나의 방법만을 설명\n",
    "      - 모델의 입력 features 수를 바꿈고 동시에 그 features와 연관된 새로운 파라미터를 더함\n",
    "  - 더 많은 방법들이 있음\n",
    "  - capacity는 모델의 선택으로만 결정되지 않음\n",
    "  - 모델은 학습 알고리즘이 학습 객체를 줄이기 위해 파라미터를 다르게 할 때로부터 선택하는 함수들의 집합을 특정함\n",
    "      - 모델의 **representatinoal capacity**라고 함\n",
    "      \n",
    "      \n",
    "  - 많은 경우 최고의 함수를 찾는 것은 매우 어려운 최적화 문제\n",
    "  - 실무에선 학습 알고리즘이 최고의 함수를 찾아주진 않지만 단지 학습 오류를 상당히 줄이는 단 하나의 함수를 찾음\n",
    "  - 이러한 최적화 할고리즘의 불완전한 한계들은 학습 알고리즘의 **effective capacity**가 모델 집합의 representational capacity보다 적을 수 있음을 의미\n",
    "  \n",
    "p16 (**page114**) :\n",
    "  - 머신 러닝 모델 일반화 향상을 위한 최근의 아이디어는 적어도 프톨레마이 시대의 철학자들에 대한 논리를 정제하는 것\n",
    "  - parsimony의 원리 -> Occam's razor\n",
    "      - 알려진 관측들을 고루 잘 설명하는 여러 가설들 중 \"가장 단순한\" 하나를 고르는 것\n",
    "      - 20세기 통계 학습 이론 정립자들에 의애 구체화됨\n",
    "      \n",
    "p17 :\n",
    "  - 통계 학습 이론은 모델 capacity를 수량화하는 여러 방향들을 제공\n",
    "      - 가장 잘 알려진 방법: **Vapnik-Chervonenkis dimension** 또는 VC dimension\n",
    "          - 이진 분류기의 capacity 측정\n",
    "          - 분류기가 무작위로 label할 수 있는 x 점들의 m 학습 ㅔㅅㅅ이 있을 때 m의 최고 값으로 정의\n",
    "    \n",
    "p18 :\n",
    "  - 모델의 capacity 수량화는 통계 학습 이론이 수량적 prediction을 하게 함\n",
    "  - 통계 학습 이론에서 가장 중요한 결과: 학습 오류와 일반화 오류 사이의 불일치는 모델 capacity가 증가함에 따라 제한되지만 학습 examples의 수가 증가할 수록 줄어듬\n",
    "  - 이런 제한은 머신 러닝 알고리즘이 동작할 수 있는 지능의 정당화를 제공하지만 딥러닝 알고리즘과 동작할 때 실제로 거의 쓰이지 않음\n",
    "      - 한계가 매우 느슨하고 딥 러닝 모델의 capacity를 결정하는 것이 어렵기 때문에 부분적임\n",
    "      - 딥 러닝 모델의 capacity 결정은 특히 어려운 문제로 효과적인 capacity는 최적화 알고리즘의 특성 제한되어있고 딥 러닝에 얽혀있는 매우 일반적인 non-convex 최적화 문제의 이론적 이해가 부족하기 때문\n",
    "      \n",
    "p19 :\n",
    "  - 더 단순한 함수들이 일반화 될 가능성이 더 높은 반면에 여전히 더 적은 학습 오류를 위한 충분히 복잡한 가설을 찾아야 함\n",
    "      - 일반적으로, 모델 capacity가 증가할 때 가능한 최소의 오류값이 나타날 때까지 학습 오류는 줄어듬\n",
    "      - 일반적으로, 일반화 오류는 모델 capacity 함수로 U-모양 곡선을 가짐 (Fig 5.3)\n",
    "  \n",
    "  <img src=\"files/figure5_3.png\" width=800px;>\n",
    "  \n",
    "  \n",
    "p20 :\n",
    "  - 가장 극잔적인 임의로 높은 capacity의 경우에 도달하기 위한 **non-parametric** 모델 개념 제시\n",
    "      - 지금까지 선형 회귀 같은 parametric 모델을 다룸\n",
    "      - parametric 모델은 어떤 데이터가 측정되기 전에 유한하고 고정된 크기의 파라미터 벡터에 의해 표현되는 함수를 학습\n",
    "      \n",
    "      \n",
    "  - non-parametric 모델은 이런 한계점이 없음\n",
    "  \n",
    "p21 (**page115**) ;\n",
    "  - 때때로, non-parametric 모델은 그저 이론적 추상화 개념으로 실전에서 쓸 수 없는 것으로 여겨짐\n",
    "      - 모든 가능한 확률 분포를 탐색하는 알고리즘\n",
    "      \n",
    "      \n",
    "  - 그러나, non-parametric 모델의 복잡도를 학습 셋 크기의 함수로 만듦으로써 실용적으로 설계 가능\n",
    "      - 예) **nearest neighbor regression**\n",
    "      - 가중치의 고정된 길이 벡터를 가지는 선형 회귀와 다르게 nearest neighbor regression 모델은 단순히 학습 셋에서 ${X}$, ${y}$를 저장\n",
    "      - 테스트 point ${x}$를 분류할 때, 모델은 학습 셋에서 가장 가까운 개체를 차자 관련 회귀 target을 반환\n",
    "      - ${\\hat{y}=y_i}$ 일 때 ${i=argmin||X_{i,:}-x||_2^2}$\n",
    "      - 학습된 거리 metric과 같은 ${L^2}$ norm 이외의 거리 metric으로 일반화될 수 있음\n",
    "      - 알고리즘이 가장 가까운 것들과 묶이는 모든 ${X_{i,:}}$에 대해 ${y_i}$ 값을 평균냄으로써 관계를 끊는다면 이 알고리즘은 어떠한 회귀 데이터셋에서 최소의 가능한 학습 오류를얻을 수 있음\n",
    "          - 두 동일한 입력이 다른 출력과 연관되어 있을 때, 0 이상일 수 있음\n",
    "          \n",
    "p22 :\n",
    "  - 마지막으로, 또한 요구되는 파라미터의 수가 증가하는 또다른 알고리즘 안에 parametric 학습 알고리즘을 묶음으로써 non-parametric 학습 알고리즘을 생성할 수 있음\n",
    "      - 예) 입력의 다항식 확장 위에서 선형 회귀로 학습된 다학식의 차수를 바꾸는 학습의 외부 loop 가정\n",
    "      \n",
    "p23 (**page116**) :\n",
    "  - 이상적인 모델은 데이터를 생성하는 true 확률 분포를 단순히 알고 있는 예언자임\n",
    "      - 그럼에도 모델은 분포에 노이즈가 섞여있을 것이기 때문에 여전히 많은 문제들에서 오류 발생\n",
    "      \n",
    "      \n",
    "  - 지도 학습의 경우 ${x}$에서 ${y}$로의 mapping은 본질적으로 확률론적이거나 $[y}$는 ${x}$에 포함되지 않은 변수들을 연관짓는 결정론적 함수\n",
    "  - true 분포 ${p(x,y}$로부터 prediction을 하는 예언자에 의해 발생한 오류는 **Bayes erro** 라 함\n",
    "  \n",
    "p24 :\n",
    "  - 학습과 일반호 ㅏ오류는 학습 셋의 크기가 다름에 따라 달라짐\n",
    "  - 예측 일반화 오류는 학습 examples의 수가 증가하여 절대 증가하지 않음\n",
    "  - non-parametric 모델에 대해 더 많은 데이터는 최고의 가능성 있는 오류가 구해질 때까지 더 나은 일반화를 나음\n",
    "  - 최적보다 적은 capacity의 고정된 parametric 모델은 점점 Bayes 오류를 초과하는 오류 값에 대응될 것\n",
    "  - Fig 5.4\n",
    "  \n",
    "  <img src=\"files/figure5_4.png\" width=800px;>\n",
    "  \n",
    "  \n",
    "  - 모델이 최적의 capacity를 갖는 것이 가능하지만 여전히 학습과 일반화 오류 사이에 큰 차이가 존재\n",
    "      - 이 경우, 학습 examples을 더 많이 모으는 것으로 차이를 줄일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 5.2.1 The No Free Lunch Theorem\n",
    "  \n",
    "  p1.\n",
    "  - 학습 이론은 머신 러닝이 한정된 examples의 학습 셋으로부터 일반화를 잘 할 것이라 주장\n",
    "      - 몇 기본 논리를 부정하는 것 ㅊ처럼 보임\n",
    "      - 한정된 examples 셋으로부터의 귀납 추리 또는 추론으로 논리적으로 맞지 않음\n",
    "      - 셋의 모든 멤버를 나타내는 법칠을 논리적으로 추혼하기 위해 모든 멤버의 정보가 필요\n",
    "  \n",
    "  p2.\n",
    "  - 부분적으로, 머신 러닝은 순수한 논리적 추리에 쓰인 적체적으로 확실한 규칙보다 확률적인 규칙만을 요구함으로써 이 문제를 회피\n",
    "  - 머신 러닝은 셋의 *대부분* 멤버에 대한 *아마도* 정확한 규칙을 찾음\n",
    "  \n",
    "  p3.\n",
    "  - 불행하게도, 이것으로 모든 문제 해결 불가\n",
    "  - **no free lunch theorem**은 모든 가능한 데이터 분포를 평균하여, 모든 분류 알고리즘은 이전에 측정되지 않은 포인트들을 분류할 때 동일한 오류를 가진다고 함\n",
    "      - 같은 의미로, 어떠한 머신 러닝 알고리즘이 서로 다른 알고리즘보다 보편적으로 더 낫다고 할 수 없음\n",
    "      - 상상할 수 있는 가장 복잡한 알고리즘은 모든 가능한 작업에 대해 동일한 평균 성능을 보이며 모든 점은 같은 클래스에 속하는 것을 단순히 예측함\n",
    "      \n",
    "  p4.\n",
    "  - 불행하게도, 이 결과들은 단지 *모든* 가능한 데이터 생성 분포를 평균할 때만 나타남\n",
    "      - 실제 응용의 확률 분포 종류에 대해 가정한다면 그 분포들에서 잘 동작하는 학습 알고리즘을 설계할 수 있ㅇ음\n",
    "      \n",
    "  p5.\n",
    "  - 머신 러닝 연구의 목적: 보편적인 학습 알고리즘이나 절대적으로 최고의 학습 알고리즘을 찾는 것이 아님\n",
    "  - #### 어떤 분포가 AI agent 가 경험하는 \"실세계\"와 연관되고 어떤 종류의 머신 러닝 알고리즘이 우리가 다룰 데이터 생성 분포의 종류로 도출되는 데이터에 잘 동작하는가를 이해하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Hyperparameters and Validation Sets\n",
    "\n",
    "p1.\n",
    "- 대부분의 머신 러닝 알고리즘들은 알고리즘의 동장을 제어할 수 있는 여러 설정사항들이 있음: **hyperparameters**\n",
    "- hyperparameter 값은 학습 알고리즘 자체로 맞춰질 수 없음 (그러나 학습 알고리즘이 또 다른 학습 알고리즘을 위해 최고의 hyperparameters를 학습하는 내재 프로시져 설계 가능)\n",
    "\n",
    "p2.\n",
    "- Fig 5.2의 다항식 회귀 예시) 하나의 hyperparameter: **capacity** hyperparameter로 동작하는 다항식의 차수\n",
    "- weight decay의 강도를 조절하는 ${\\lambda}$\n",
    "\n",
    "p3.\n",
    "- 가끔 설정이 최적화가 어려워 학습 알고리즘이 학습하지 않은 hyperparameter로 선택됨\n",
    "- 더 빈번하게, 학습 셋에서 그 hyperparameter를 학습하기 적절하지 않기 때문에 그 설정을 hyperparameter가 되어야함\n",
    "    - 모든 hyperparameters 적용\n",
    "    - 학습 셋에서 학습: 항상 maximum 가능 모델 capacity 선택 => overfitting (Fig 5.3)\n",
    "        - 예) 다항식 낮은 차수, weight of decay > 0 보다 weight of decay ${\\lambda=0}$, 다항식의 차수가 높을 수록 학습 셋에 더 잘 맞음\n",
    "\n",
    "p4. (121p)\n",
    "- 문제해결: 학습 알고리즘은 찾을 수 없는 examples의 **validation set**\n",
    "\n",
    "p5.\n",
    "- 일찍이 학습 셋으로 동일한 분포에서 나온 examples로 구성된 테스트 셋이 학습 프로세스가 종료된 수 어떻게 학습자의 일반화 오류를 추정하는데 쓰이는지 다룸\n",
    "- hyperparameters를 포함하여  테스트 examples는 모델에 대한 결정을 어느 것도 한지 않는 다는 것이 중요\n",
    "    - 테스트 셋 example은 validation set에 쓰이지 못함\n",
    "    - 항상 *학습* 셋에서 validation set 구성\n",
    "\n",
    "\n",
    "- 학습 셋을 공통 부분이 없게 둘로 나눔\n",
    "    - 하나의 subset: 파라미터 학습\n",
    "    - 나머지 subset: validation set => 학습 전후로 일반화 오류 추정, 그에 따라 hyperparameters 업데이트\n",
    "  \n",
    "  \n",
    "- 파라미터 학습 데이터 서브셋: 학습셋 (전체 학습 프로세스에 쓰이는 더 큰 데이터 풀과 혼동 가능)\n",
    "- validation set: hyperparameters 선택을 가이드하는 데이터 서브셋\n",
    "    - 주로, 학습 데이터 80%: 학습, 20% validation\n",
    "    \n",
    "\n",
    "- 검증 셋이 hyperparameters를 \"학습\"시키기 때문에 학습 오류보다 적은 양일지라도 검증 셋 오류는 일반화 오류를 너무 적게 잡음\n",
    "- hyperparameter 최적화 완료 후 일반화 오류는 테스트 셋으로 추정될 수 있음\n",
    "\n",
    "p6.\n",
    "- 실제로, 몇 년 동안 같은 테스트 셋이 계속 다른 알고리즘 성능 평가에 쓰이고 특히 과학 사회에서 테스트 셋의 최신 성능을 넘는 시도를 고려한다면, 결국 테스트 셋에 대해 낙관적일 것\n",
    "- 벤치마크는 김 빠질 것이고 학습된 시스템의 true 현장 성능을 반영하지 못함\n",
    "- 사회는 더 새롭고 더 큰 데이터셋으로 옮겨가는 경향이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Cross-Validation\n",
    "p1. (122p)\n",
    "- 테스트 셋이 작아지는 결과가 된다면 고정된 학습 셋, 테스트 셋으로 나누는 것은 문제\n",
    "    - 작은 테스트 셋은 추정된 평균 테스트 오류 주변의 통계적 불확실성을 나타내며 다른 알고리즘보다 좋은 성능을 낸다고 하기 어려움\n",
    "    \n",
    "p2.\n",
    "- 데이터셋에 수백 수천 이상의 examples가 있을 때 큰 문제 아님\n",
    "- 데이터셋이 너무 작으면 대안 절차로 연산 cost를 증가시키고 모든 examples를 평균 테스트 오류 추정에 사용\n",
    "    - 이 절차는 다른 무작위로 선택된 서브셋 또는 원 데이터셋 분할에 대한 학습, 테스트 연산을 반복하는 아이디어에 기반\n",
    "    - 가장 흔한 절차: Alg 5.1에 나와 있는 *k*-fold cross-validation\n",
    "        - k-fold cross-validation: 데이터 셋을 겹치지 않는 k개의 서브셋으로 나눈 것\n",
    "\n",
    "\n",
    "- 테스트 오류는 *k*번 시도 동안 평균 테스트 오류를 통해 추정될 수 있음\n",
    "    - i번째 시도, i번 째 서브셋은 테스트 셋, 나머지 데이터는 학습 셋\n",
    "    - 한 가지 문제점: 평균 오류 추정자 분산의 unbiased 추정자가 없으니 근사치 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 5.2.2 Regularization\n",
    "  p1.\n",
    "  - no free unch 이론은 특정한 일에 잘 동작하는 머신 러닝 알고리즘을 설계해야함을 의미\n",
    "      - 머신 러닝 알고리즘에 선호도 셋을 만듦\n",
    "      - 선호도가 학습 문제와 같은 선상에 놓일 때 알고리즘은 더 잘 동작\n",
    "  \n",
    "  p2.\n",
    "  - 학습 알고리즘이 더 잘 동작하게 하는 방법으로 머신 러닝이 선택할 수 있는 솔루션의 가정 공간으로부터 함수를 더하거나 뺌으로써 모델의 representational capacity를 늘리거나 줄이는 것\n",
    "      - 회귀 문제의 다항식 차수 가감의 예시를 들었음\n",
    "      - 예시는 너무 단순화됨\n",
    "      \n",
    "  p3.\n",
    "  - 알고리즘의 동작은 가설 공간에서 허락된 함수 셋의 크기 뿐만 아니라 그 함수들의 특정 identity에 강하게 영향 받음\n",
    "  - 선형 회귀 학습 알고리즘은 입력의 선형 합수 셋으로 구성된 가설 공간을 가짐\n",
    "  - 이 선형 함수들은 입출력 간 관계가 선형에 가까울 문제에 매우 유용\n",
    "      - 비선형일 경우 덜 효율적\n",
    "          - 예) ${sin(x)}$를 예츨할 때 선형 회귀는 잘 동작 안함\n",
    "          \n",
    "          \n",
    "  - 어떤 종류의 함수로부터 솔류션을 도출할 수 있을지 선택할 뿐만 아니라 함수들의 수를 조절함으로써 알고리즘의 성능 조절 가능\n",
    "  \n",
    "  p4.\n",
    "  - 하나의 학습 알고리즘에 가설 공간에 다른 공간으로 하나의 솔루션에 대한 선호를 부여\n",
    "      - 두 함수 모두 유효하지만 하나만 선호됨을 의미\n",
    "      - 선호되지 않은 솔루션은 선호되는 솔루션보다 상당히 학습 데이터가 맞을 경우에만 선택\n",
    "      \n",
    " p5. (119p)\n",
    " - 예) 선형 회귀 학습 조건을 **weight decay**를 갖도록 수정\n",
    "     - weight decay로 선형 회귀를 수행하기 위해, 학습과 criterion 함수 둘 다의 MSE로 구성된 합을 최소화\n",
    "         - criterion ${J(w)}$: 더 작은 ${L^2}$ norm을 갖기 위한 weight 선호\n",
    "         \n",
    " \n",
    " $${J(w)=MSE_{train}+\\lambda{w^T}w}$$\n",
    " \n",
    " \n",
    "- ${\\lambda}$: 더 작은 가중치를 위한 선호 강도 조절하는 미리 정해진 값\n",
    "    - ${\\lambda=0}$: no preference\n",
    "    - 더 큰 ${\\lambda}$: 가중치 작게\n",
    "         \n",
    "         \n",
    "- ${J(w)}$ 최소화: 학습 데이터 fitting과 감소 사이의 tradeoff\n",
    "    - 더 작은 경사 또는 더 적은 feature에 가중치 부여\n",
    "    - 예) 다른 ${\\lambda}$값으로 고차 다항 회귀 모델을 학습 -> Fig 5.5\n",
    "    \n",
    "<img src=\"files/figure5_5.png\" width=800px;>\n",
    "\n",
    "\n",
    "p6. (120p)\n",
    "- 더 일반적으로, cost function에 **regularizer** 라는 패널티를 더함으로써 함수 ${f(x;\\theta)}$를 학습하는 모델 정규화 가능\n",
    "- weight decay의 경우, regularizer: ${\\Omega(w)=w^{T}w}$\n",
    "- 7장에서 많은 regularizer 다룰 예정\n",
    "\n",
    "p7.\n",
    "- 하나의 함수에서 다른 함수로 선호를 표현하는 것은 가설 공간에서 멤버를 포함하고 제외하는 것 보다 모델 capacity 조절에 더 일반적\n",
    "    - 함수를 가설 공간에서 제외: 그 함수에 반대되는 무한히 강한 선호\n",
    "\n",
    "p8.\n",
    "- weight decay 예) 명쾌하게 작아진 weights와 정의된 선형 함수들에 대한 선호를 최소화한 기준에 추가적 용어를 통해 표현\n",
    "- 암시적으로, 명시적으로 나타내는 여러 방법들이 있음: **regularization**\n",
    "- *정규화는 일반화 오류를 줄이려하지만 학습 오류에는 그렇지 않은 알고리즘의 어떠한 수정사항을 의미*\n",
    "- 최적화 문제와 마찬가지로 머신 러닝의 중심적 문제\n",
    "\n",
    "p9.\n",
    "- no free lunch theorem은 최고의 머신 러닝 알고리즘은 없으며 특히 정규화의 최고 형태는 없음을 명확히함\n",
    "    - 대신 특정 작업에 잘 되는 것을 찾으면 됨\n",
    "    \n",
    "    \n",
    "- 이 책에서 제시하는 딥 러닝 철학은 광범위의 사람이 할 수 있는 모든 지능적 업무를 매우 일반적 목적 형태의 정규화로 효과적으로 해결하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Hyperparameters and Validation Sets\n",
    "\n",
    "p1.\n",
    "- 대부분의 머신 러닝 알고리즘들은 알고리즘의 동장을 제어할 수 있는 여러 설정사항들이 있음: **hyperparameters**\n",
    "- hyperparameter 값은 학습 알고리즘 자체로 맞춰질 수 없음 (그러나 학습 알고리즘이 또 다른 학습 알고리즘을 위해 최고의 hyperparameters를 학습하는 내재 프로시져 설계 가능)\n",
    "\n",
    "p2.\n",
    "- Fig 5.2의 다항식 회귀 예시) 하나의 hyperparameter: **capacity** hyperparameter로 동작하는 다항식의 차수\n",
    "- weight decay의 강도를 조절하는 ${\\lambda}$\n",
    "\n",
    "p3.\n",
    "- 가끔 설정이 최적화가 어려워 학습 알고리즘이 학습하지 않은 hyperparameter로 선택됨\n",
    "- 더 빈번하게, 학습 셋에서 그 hyperparameter를 학습하기 적절하지 않기 때문에 그 설정을 hyperparameter가 되어야함\n",
    "    - 모든 hyperparameters 적용\n",
    "    - 학습 셋에서 학습: 항상 maximum 가능 모델 capacity 선택 => overfitting (Fig 5.3)\n",
    "        - 예) 다항식 낮은 차수, weight of decay > 0 보다 weight of decay ${\\lambda=0}$, 다항식의 차수가 높을 수록 학습 셋에 더 잘 맞음\n",
    "\n",
    "p4. (121p)\n",
    "- 문제해결: 학습 알고리즘은 찾을 수 없는 examples의 **validation set**\n",
    "\n",
    "p5.\n",
    "- 일찍이 학습 셋으로 동일한 분포에서 나온 examples로 구성된 테스트 셋이 학습 프로세스가 종료된 수 어떻게 학습자의 일반화 오류를 추정하는데 쓰이는지 다룸\n",
    "- hyperparameters를 포함하여  테스트 examples는 모델에 대한 결정을 어느 것도 한지 않는 다는 것이 중요\n",
    "    - 테스트 셋 example은 validation set에 쓰이지 못함\n",
    "    - 항상 *학습* 셋에서 validation set 구성\n",
    "\n",
    "\n",
    "- 학습 셋을 공통 부분이 없게 둘로 나눔\n",
    "    - 하나의 subset: 파라미터 학습\n",
    "    - 나머지 subset: validation set => 학습 전후로 일반화 오류 추정, 그에 따라 hyperparameters 업데이트\n",
    "  \n",
    "  \n",
    "- 파라미터 학습 데이터 서브셋: 학습셋 (전체 학습 프로세스에 쓰이는 더 큰 데이터 풀과 혼동 가능)\n",
    "- validation set: hyperparameters 선택을 가이드하는 데이터 서브셋\n",
    "    - 주로, 학습 데이터 80%: 학습, 20% validation\n",
    "    \n",
    "\n",
    "- 검증 셋이 hyperparameters를 \"학습\"시키기 때문에 학습 오류보다 적은 양일지라도 검증 셋 오류는 일반화 오류를 너무 적게 잡음\n",
    "- hyperparameter 최적화 완료 후 일반화 오류는 테스트 셋으로 추정될 수 있음\n",
    "\n",
    "p6.\n",
    "- 실제로, 몇 년 동안 같은 테스트 셋이 계속 다른 알고리즘 성능 평가에 쓰이고 특히 과학 사회에서 테스트 셋의 최신 성능을 넘는 시도를 고려한다면, 결국 테스트 셋에 대해 낙관적일 것\n",
    "- 벤치마크는 김 빠질 것이고 학습된 시스템의 true 현장 성능을 반영하지 못함\n",
    "- 사회는 더 새롭고 더 큰 데이터셋으로 옮겨가는 경향이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Cross-Validation\n",
    "p1. (122p)\n",
    "- 테스트 셋이 작아지는 결과가 된다면 고정된 학습 셋, 테스트 셋으로 나누는 것은 문제\n",
    "    - 작은 테스트 셋은 추정된 평균 테스트 오류 주변의 통계적 불확실성을 나타내며 다른 알고리즘보다 좋은 성능을 낸다고 하기 어려움\n",
    "    \n",
    "p2.\n",
    "- 데이터셋에 수백 수천 이상의 examples가 있을 때 큰 문제 아님\n",
    "- 데이터셋이 너무 작으면 대안 절차로 연산 cost를 증가시키고 모든 examples를 평균 테스트 오류 추정에 사용\n",
    "    - 이 절차는 다른 무작위로 선택된 서브셋 또는 원 데이터셋 분할에 대한 학습, 테스트 연산을 반복하는 아이디어에 기반\n",
    "    - 가장 흔한 절차: Alg 5.1에 나와 있는 *k*-fold cross-validation\n",
    "        - k-fold cross-validation: 데이터 셋을 겹치지 않는 k개의 서브셋으로 나눈 것\n",
    "\n",
    "\n",
    "- 테스트 오류는 *k*번 시도 동안 평균 테스트 오류를 통해 추정될 수 있음\n",
    "    - i번째 시도, i번 째 서브셋은 테스트 셋, 나머지 데이터는 학습 셋\n",
    "    - 한 가지 문제점: 평균 오류 추정자 분산의 unbiased 추정자가 없으니 근사치 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Estimator, Bias, and Variance\n",
    "\n",
    "p2 (page 122)\n",
    "* 통계 분야는 training set뿐만 아니라 일반화에 대한 문제를 해결하는 머신러닝의 목표를 달성하는데 사용할 수 있는 많은 도구를 제공함\n",
    "* parameter estimation, bias, 그리고 variance와 같은 개념들은 일반화, overfitting, underfitting의 개념을 표현하는데 유용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Point Estimation\n",
    "\n",
    "p1 \n",
    "* point estimation(점 추정)은 어떤 양에서 가장 최상의 단일 예측값을 제공하는 추정법임\n",
    "* 실제값에서 매개변수 예측값을 구별하기 위해서 매개변수 θ의 점추정값을 θ로 표현함\n",
    "\n",
    "p2 \n",
    "* m개의 독립적이고 Identically(동일한? 형식이 동일?)한 데이터 { \\\\(x^{(1)}, ..., x^{(m)} \\\\) }가 있다고 하자\n",
    "* 점추정방법은 다음과 같은 데이터의 함수임\n",
    "\n",
    "![pic01](https://user-images.githubusercontent.com/19326012/76193826-32e05d00-6228-11ea-8a75-b1c5ffc06aab.PNG)\n",
    "p3 **(page 124)**\n",
    "* 이 함수에 대한 정의는 g가 실제 θ값에 가까운 값을 반환하거나 g의 범위가 허용가능한 값θ와 동일한 범위를 반환하지 않아도 됨\n",
    "* 점추정에 대한 이 정의는 매우 general하고 좋은 estimator의 설계에 있어서 매우 유연함\n",
    "* 이렇게 유연하기 때문에 대부분의 함수가 estimator로 적합하지만 좋은 추정기는 output이 훈련데이터를 생성한 실제 값에 가까운 함수임\n",
    "\n",
    "p4 \n",
    "* 실제값 θ는 고정되어있지만, 알려지지않은 것으로 가정하고, 점 추정값 θ가 데이터의 함수를 통해 추정된 값으로 가정함\n",
    "* 데이터는 임의의 프로세스에서 추출되기때문에 데이터의 모든 함수는 또한 임의의값을 가짐\n",
    "* 따라서 가변변수를 θ에 햇을 붙여 표현함\n",
    "\n",
    "p5 \n",
    "* 점추정은 또한 input 변수와 target변수 사이의 관계를 추정하는데 참고가 될 수 있음\n",
    "\n",
    "p6\n",
    "* 위에서 언급했다싶다, 때때로 우리는 function estimation을 수행하는 데 관심있을 때가 있음\n",
    "* 주어진 벡터 x로부터 변수 y를 예측한다고 하자\n",
    "* 여기서 x와 y의 관계를 근사하는 함수 f(x)가 있다고 가정하자\n",
    "* 예를 들어 y = f(x) + a라는 식이 있을 때, a는 x에 의해 표현될 수 없는 y값들을 나타낸다고 하자\n",
    "* 여기서 우리는 f라는 함수를 근사화하는데 관심이 있음\n",
    "* 함수 f를 예측하는 것은 매개변수 θ를 예측하는 것과 똑같은데, 예측된 함수 \\\\(\\hat{f} \\\\)는 이 함수영역에서 하나의 점추정값일 뿐임\n",
    "* 선형회기의 예시와 polynomial regression(다항식 회기)예시는 매개변수 w를 예측하거나 x에서 y로 맵핑되는 함수 (\\hat{f} \\\\)를 예측하는 것을 해석하는 시나리오의 예시가 될 것임\n",
    "* 이제, 점추정방법의 가장 일반적으로 연관되는 특성을 검토하고 이러한 추정법에 대해 알려주는 내용에 대해 논의함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 Bias\n",
    "p1\n",
    "* 추정기의 Bias는 다음과 같이 정의됨\n",
    "![pic02](https://user-images.githubusercontent.com/19326012/76205956-92496780-623e-11ea-8628-f1d86b9f61e0.PNG)\n",
    "* 여기서 기댓값은 랜덤변수에 대한 값이고, θ는 데이터 생성 분포를 정의하는데 사용되는 θ의 실제 값임\n",
    "* 만약 bias \\\\((\\hat{θ}_m \\\\)) = 0이라면 추정기 \\\\((\\hat{θ}_m \\\\))는 unbiased하다 즉 편향되지 않다라고 함\n",
    "* \\\\(lim_{m->\\infty} \\\\)bias(\\\\((\\hat{θ}_m \\\\))) = 0일때, 추정기 \\\\((\\hat{θ}_m \\\\)) 는 점근적인 비편향이라고 함\n",
    "\n",
    "p2 **(page 125)**\n",
    "#### example: Bernoulli Distribution\n",
    "* 데이터 샘플 {\\\\(x^{(1)},..., x^{(m)}) \\\\)}가 서로 독립적이고, Identical하며 평균 θ로 베르누이 분포에 따라 분포해있다고 하면\n",
    "![pic03](https://user-images.githubusercontent.com/19326012/76212613-38e83500-624c-11ea-84e2-4e55d71b7209.PNG) \n",
    "* {\\\\(x^{(1)},..., x^{(m)}) \\\\)}의 값이 θ가 되는 확률을 나타냄\n",
    "* 베르누이 분포에서 매개변수 θ에 대한 추정은 훈련 샘플의 평균임\n",
    "![pic21](https://user-images.githubusercontent.com/19326012/76376502-c9795f00-638b-11ea-9fba-0c175047f3ab.PNG)\n",
    "출처: https://datascienceschool.net/view-notebook/76644ecf24154db687392ccb0eaac644/\n",
    "![pic04](https://user-images.githubusercontent.com/19326012/76213032-1f93b880-624d-11ea-8292-8b6b3737183d.PNG)\n",
    "* 이 추정기가 편향적인지 결정하기 위해서 식 5.22에서 식 5.20을 빼서 확인함\n",
    "![pic05](https://user-images.githubusercontent.com/19326012/76213099-4baf3980-624d-11ea-8719-5c51955c1187.PNG)\n",
    "* bias(\\\\((\\hat{θ}_m \\\\))) = 0이기 때문에 추정기 \\\\(\\hat{θ} \\\\)는 편향적이지 않음\n",
    "\n",
    "#### example: Gaussian Distribution Estimator of the Mean\n",
    "* 데이터 샘플 {\\\\(x^{(1)},..., x^{(m)}) \\\\)}가 서로 독립적이고, Identical하며 가우시안 분포에 따라 분포해있다고 하면 P({\\\\( x^{(i)})\\\\)} = \\\\((\\mathcal{N}\\\\)(\\\\( x^{(i)}\\\\);u,\\\\(\\sigma^2 \\\\))\n",
    "* 가우시안 확률 밀집 함수는 다음과 같음\n",
    "![pic06](https://user-images.githubusercontent.com/19326012/76214508-3ab3f780-6250-11ea-87be-46ff911fc02c.PNG)\n",
    "* 가우시안 확률 분포에서 매개변수 θ에 대한 추정은 훈련 샘플의 평균임\n",
    "![pic07](https://user-images.githubusercontent.com/19326012/76215430-16591a80-6252-11ea-8692-73b68908f922.PNG)\n",
    "* 샘플 평균의 편향성을 결정하기 위해 샘플 평균의 기댓값을 알아냄\n",
    " ![pic08](https://user-images.githubusercontent.com/19326012/76217421-bfeddb00-6255-11ea-9bc9-545f139ef6fb.PNG)\n",
    "* 따라서 샘플평균은 편향적이지 않다라는 것을 알아냄\n",
    "\n",
    "#### Example: Estimators of the Variance of a Gaussian Distribution\n",
    "* 가우시안 분포에 따른 분산 \\\\(\\sigma^2 \\\\)에 대한 두개의 다른 추정기에 대해 비교해 볼 것임\n",
    "* 첫번째 \\\\(\\sigma^2 \\\\)의 추정기는 단순한 분산임\n",
    "![pic09](https://user-images.githubusercontent.com/19326012/76263977-b12e1500-62a3-11ea-9752-d08c6081818f.PNG)\n",
    "* 여기서 \\\\(\\hat{u}_m \\\\)는 샘플의 평균이고 위의 식에서 우리는 분산이 편향적인지 알고싶기 때문에 다음과같이 식을 세울 수 있음\n",
    "![pic10](https://user-images.githubusercontent.com/19326012/76264078-0bc77100-62a4-11ea-8cc9-72116a6a3b93.PNG)\n",
    "* 여기서 \\\\(\\mathbb{E} \\\\)[\\\\(\\sigma_m^2 \\\\)]을 먼저 풀어보면\n",
    "![pic11](https://user-images.githubusercontent.com/19326012/76264341-e38c4200-62a4-11ea-8962-8a62e395ed1c.PNG)\n",
    "* 식 5.37로 돌아가서, \\\\(\\sigma_m^2 \\\\)에 대한 bias는 -\\\\(\\sigma_m^2 \\\\)/m이라는 것을 알 수 있음 따라서 단순한 분산은 편향적인 추정기임\n",
    "* 다음과 같은 **비편향적인 단순한 분산 추정기** 다른 접근법을 제공함\n",
    "![pic12](https://user-images.githubusercontent.com/19326012/76264752-01a67200-62a6-11ea-82d8-9ec6fe9299b0.PNG)\n",
    "* 이름에서 알 수 있듯이 이 추정기는 비편향적임\n",
    "* 즉, 식 5.37에 의해 \\\\(\\mathbb{E} \\\\)[\\\\(\\sigma_m^2 \\\\)] = \\\\(\\sigma_m^2 \\\\)를 찾을 수 있음 \n",
    "![pic13](https://user-images.githubusercontent.com/19326012/76265137-1d5e4800-62a7-11ea-8d50-9bb266c2065d.PNG)\n",
    "* 여기서 두가지 추정기에 대해 확인해 봤는데 하나는 편향적이였고 하나는 편향적이지 않았음\n",
    "* 비편향적인 추정기의 경우 이상적이였던 반면, 이 비편향적인 추정기는 항상 최상의 추정기가 될 수는 없음\n",
    "* 앞으로 불 수 있듯이 종종 다른 중요한 특성을 가진 편향 추정기를 사용할 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.3 Variance and Standard Error\n",
    "p1 **(page 127)**\n",
    "* 고려하고자 하는 추정기의 또다른 특성은 데이터 샘플의 함수에 따라 얼마나 달라지는지 예측하는 것임\n",
    "* 추정기의 편향성을 결정하기 위한 추정기의 기댓값을 계산함으로써 추정기의 분산을 계산할 수 있음\n",
    "* 추정기의 분산은 단순하게 분산이라 하고 Var\\\\((\\hat{θ} \\\\))라 부름\n",
    "* 위의 분산은 임의의 변수들이 학습데이터셋으로 사용되었음\n",
    "* 분산의 제곱근은 표준편차라 하며 SE\\\\((\\hat{θ} \\\\))로 표현함\n",
    "\n",
    "p2 **(page 128)**\n",
    "* 추정기의 분산이나 표준편차는 기본 데이터 생성 프로세스에서 데이터셋을 독립적으로 다시 샘플링할 때, 데이터에서 계산한 추정치가 어떻게 달라질 지에 대한 측정값을 제공함 --> 분산이나 표준편차를 이용하면 샘플링데이터가 달라져도 추정치가 어떻게 달라지는지 측정할 수 있다는 의미\n",
    "* 추정기의 바이어스가 낮으면 좋은것 처럼 분산도 상대적으로 낮으면 좋음\n",
    "\n",
    "p3\n",
    "* 유한한 수의 샘플을 이용하여 통계를 계산할 때, 동일한 분포에서 다른 표본을 얻을 수 있고 통계가 달라졌다는 점에서 실제 기본 매개변수에 대한 추정치는 불확실함\n",
    "* 추정기에서 예상되는 오차의 정도는 정량화하려는 오차의 원인이 됨\n",
    "\n",
    "p4\n",
    "* 평균의 표준오차는 다음과 같음\n",
    "![pic14](https://user-images.githubusercontent.com/19326012/76267115-0c183a00-62ad-11ea-9397-8f2bda8dfe29.PNG)\n",
    "* 여기서 \\\\(\\sigma^2 \\\\)은 샘플 \\\\(x^i\\\\)에 대한 분산임\n",
    "* 표준오차는 보통 \\\\(\\sigma \\\\)를 계산함으로써 계산되어짐\n",
    "* 표준 분산의 제곱근이나 비편향 추정기의 분산에 대한 제곱근을 이용해서는 표준편차의 비편향 추정을 할 수 없음\n",
    "* 그래서 큰 m에 대해 근사하는 것이 가장 합리적임\n",
    "\n",
    "p5\n",
    "* 평균의 표준오차는 기계학습 실험에 매우 유용함\n",
    "* 특히 일반화 오류를 추정할때 유용한데, 테스트 셋에서 오류의 표본평균을 계산할때 쓰임\n",
    "* 평균이 정규분포와 함께 사용되면 중심 한계 정리를 활용하여 실제 기대치가 선택한 간격에 해당할 확률을 계산할 수 있음\n",
    "* 예를 들어, 평균 \\\\((\\hat{u}_m \\\\))에 대한 95%신뢰도를 가지는 간격은 다음과 같음\n",
    "![pic15](https://user-images.githubusercontent.com/19326012/76268645-0cff9a80-62b2-11ea-91c9-7a33bee5d609.PNG)\n",
    "* 기계학습 실험에서 알고리즘A의 오류에 대한 95% 신뢰구간의 상한이 알고리즘B의 오류에 대한 95%신뢰고간의 하한보다 작으면 알고리즘A가 알고리즘 B보다 낫다고 함\n",
    "\n",
    "p6 **(page 129)**\n",
    "#### Example: Bernoulli Distribution\n",
    "* 위에서 했던것과 같이 베르누이 분포를 가지는 독립적이고 indeltical한 데이터 {\\\\(x^{(1)} \\\\),..., \\\\(x^{(m)} \\\\)}가 있다고 하자\n",
    "* 이전과 다르게 이번에는 추정량 \\\\(\\hat{θ}_m \\\\) = 1/m * \\\\(\\sum_{i=0}^m x^{(i)} \\\\) 에 대한 분산을 계산해보자\n",
    "![pic16](https://user-images.githubusercontent.com/19326012/76271572-45a47180-62bc-11ea-89c9-cbe45d640e4d.PNG)\n",
    "* 추정량의 분산은 데이터셋의 example의 갯수인 변수 m에 따라 감소함\n",
    "* 이런 성질을 일관성에 대해 이야기할때 흔히 나오는 이야기임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.4 Trading off Bias and Variance to Minimize Mean Squared Error\n",
    "p1 \n",
    "* bias와 분산은 추정량에서 서로 다른 두가지 오차 원인을 측정함\n",
    "* 바이어스는 함수 또는 매개변수의 실제값에서 에쌍되는 편차를 측정\n",
    "* 분산은 데이터의 특정 샘플링의 추정량 값과의 편차를 측정\n",
    "\n",
    "p2\n",
    "* bias가 더 많은 추정량과 분산이 더 많은 추정량, 두 추정량 사이에서 선택이 주어졌을때 어떻게 될까? 그리고 어떤 선택을 해야할까?\n",
    "* 예를 들어 다음과 같은 5.2그림에서 함수를 근사하는데 관심이 있고 큰 bias가 있는 모델과 큰 분산을 가진 모델중에서 하나를 선택해야한다고 해보자.\n",
    "![pic17](https://user-images.githubusercontent.com/19326012/76272682-67ebbe80-62bf-11ea-8103-32b5118d68e7.PNG)\n",
    "* 어떤 선택을 하는게 좋은가?\n",
    "\n",
    "p3\n",
    "* 이런 trade-off를 생각하는데 가장 흔한 방법은 cross-validation(교차검증)을 사용하는 것임\n",
    "* 교차검증은 많은 많은 작업에서 성공적으로 쓰이고 있음\n",
    "* 또는 추정량의 Mean Sqared error(MSE)를 사용하여 비교할 수도 있음\n",
    "![pic18](https://user-images.githubusercontent.com/19326012/76273015-227bc100-62c0-11ea-83bb-103d2571c6a4.PNG)\n",
    "* MSE는 매개변수 θ에 대한 실제값과 추정량사이에서 예상되는 편차를 측정함\n",
    "* 식 5.54에서 볼 수 있듯이, MSE를 평가할 때 bias와 분산을 같이 씀\n",
    "* 이상적인 추정량은 작은 MSE를 가지고 bias와 분산을 어느 정도 점검할 수 있는 것이여야 함\n",
    "\n",
    "p4 **(page 130)**\n",
    "* bias와 분산의 관계는 capacity, underfitting, overfitting의 머신러닝 개념과 밀접한 관계를 가짐\n",
    "* 일반화 오류가 MSE에 의해 측정되는 경우, capacity를 늘리면 분산이 증가하고 bias가 감소하는 경향을 가짐\n",
    "* 그림 5.6을 보면 용량 U형태의 일반화 오류그래프를 볼 수 있음\n",
    "![pic19](https://user-images.githubusercontent.com/19326012/76274083-ebf37580-62c2-11ea-97ef-f80998dd69c9.PNG)\n",
    "* 그림을 보면 capacity가 높아 질수록 bias는 내려가고 분산을 올라감\n",
    "* capacity를 다양화한다면, 일반화오류가 가장 낮은 optomal capacity를 찾을 수 있는데, optimal capacity보다 낮으면 underfitting, 높으면 overfitting이라 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val-score \n",
      "[1.         0.96666667 0.93333333 0.9        1.        ]\n",
      "cross-val-score.mean \n",
      "0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinwo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jinwo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\jinwo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jinwo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\jinwo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jinwo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\jinwo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jinwo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\jinwo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jinwo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# dataset\n",
    "iris = load_iris()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=5) # model, train, target, cross validation\n",
    "#5겹 교차 검층\n",
    "print('cross-val-score \\n{}'.format(scores))\n",
    "print('cross-val-score.mean \\n{:.3f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.5 Consistency\n",
    "p1\n",
    "* 지금까지는 고정된 크기의 training set에 대한 다양한 추정량의 특성에 대해 논의함\n",
    "* 일반적으로, training data의 양이 증가함에 따라 추정량의 특성에 대해 관심이 있었음\n",
    "* 특히 데이터셋에서 데이터 포인트의 수가 증가할수록(데이터의 feature가 증가?) 점추정방법이 추정한 추정값이 해당 데이터 포인트에 수렴되야함 --> 즉, 데이터셋에서 데이터의 특징을 잘 잡아 추정을 잘 해야한다\n",
    "![pic20](https://user-images.githubusercontent.com/19326012/76274522-4214e880-62c4-11ea-8af1-57ead179325a.PNG)\n",
    "* plim은 확률이 한 값으로 수렴한다는 의미이며 식 5.55는 m이 무한이 커짐에 따라 P(|\\\\((\\hat{θ}_m \\\\) - θ| > \\\\(\\varepsilon \\\\) ) --> 0 즉, θ의 편차가 \\\\(\\varepsilon \\\\)보다 클 확률은 m이 무한대로 커진다면 0에 수렴한다는 뜻임\n",
    "* 식 5.55에서 설명된 조건은 consistency(일관성)임\n",
    "* θ에 대한 추정량이 θ에 수렴하면 강한 일관성(strong consistency)을 가진다고 하고 그 반대이면 약한 추정량(weak consistency)을 가진다고 함\n",
    "\n",
    "p2\n",
    "* 일관성은 데이터 샘플의 수가 증가할수록 추정량에 의해 발생하는 bias가 감소되도록 함\n",
    "* 하지만 bias가 감소한다고해도 샘플수가 증가했다고 볼 수는 없음\n",
    "* 예를 들어 데이서셋  { \\\\(x^{(1)}, ..., x^{(m)} \\\\) }에서 정규분포 \\\\((\\mathcal{N}\\\\)(\\\\( x \\\\);u,\\\\(\\sigma^2 \\\\))를 따르는 평균 매개변수 u를 예측한다고 하자\n",
    "* 데이터셋의 첫 샘플 데이터인 \\\\(x^{(1)} \\\\)를 비편향적인 추정량으로써 \\\\(\\hat{θ} \\\\) = \\\\(x^{(1)} \\\\)라 하고\n",
    "* 이 경우, \\\\(\\mathbb{E} \\\\)(\\\\(\\hat{θ}_m \\\\)) = θ이고 따라서 추정량은 데이터의 수와 무관하게 비편향적임\n",
    "* 하지만 m이 무한히 커질때 \\\\((\\hat{θ}_m \\\\) --> θ에 대한 경우가 아니므로 일관성을 가진 추정량이라고는 할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.11 Challenges Motivating Deep Learning\n",
    "\n",
    "p1 (**page**) :\n",
    "+ 이 장에서 설명하는 간단한 기계학습 알고리즘은 많은 기능을 수행할 수 있지만, 음성인식과 물체 인식과 같은 AI의 주요 문제에서는 성공하지 못했다.\n",
    "\n",
    "p2 :\n",
    "+ AI의 주요 문제를 일반화 하기 힘든 기존의 전통적인 알고리즘(ex 룰-베이스)들은 딥러닝 개발의 동기가 되었다.\n",
    "\n",
    "p3 :\n",
    "+ 이 장에서는 고차원 데이터가 기존의 전통적인 기계학습 알고리즘에서 잘 동작하지 않는다는 것을 설명한다.\n",
    "+ 전통적인 기계학습 알고리즘은 고차원 계산에 아주 많은 비용(Cost)를 쓰지만, 딥러닝은 이러한 장애물들을 피해가도록 설계되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
